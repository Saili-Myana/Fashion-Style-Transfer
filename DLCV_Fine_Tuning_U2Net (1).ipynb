{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bxhy0XnRgvdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7LBzJJI4P9b",
        "outputId": "e1e640ba-2002-4f7b-d1b0-034ba0d6beef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch==2.1 in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch==2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install gdown"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qomyz7Tg4Wng",
        "outputId": "630eda14-0e73-4f72-d7a7-fe1be7b4e716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m842.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.13.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.11.17)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kaggle"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLXqwUxB5vdI",
        "outputId": "8e6728e1-0e77-47d8-83b2-4e242ed4db6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.5.16)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "MhQYJA6V6TSo",
        "outputId": "082b5fa0-563f-48df-c11a-a6c99edb71c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4803fc07-0ae2-4be9-acdb-e97e0f9d31b0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4803fc07-0ae2-4be9-acdb-e97e0f9d31b0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "jgZWCXfF6vAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List available datasets\n",
        "!kaggle datasets list\n",
        "\n",
        "# Download a dataset\n",
        "!kaggle competitions download -c imaterialist-fashion-2019-FGVC6\n",
        "\n",
        "# Unzip the downloaded dataset\n",
        "!unzip -q imaterialist-fashion-2019-FGVC6.zip -d ./dataset\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alM6QKRo6zNC",
        "outputId": "3b9ca252-3a04-4333-8a30-a0975bc77d88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                    title                                            size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "-----------------------------------------------------  ----------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "thedrcat/daigt-v2-train-dataset                        DAIGT V2 Train Dataset                           29MB  2023-11-16 01:38:36           1101        119  1.0              \n",
            "muhammadbinimran/housing-price-prediction-data         Housing Price Prediction Data                   763KB  2023-11-21 17:56:32           4046         81  1.0              \n",
            "maso0dahmed/video-games-data                           Video Games Data                                  5MB  2023-11-25 19:08:46           1090         34  1.0              \n",
            "carlmcbrideellis/llm-7-prompt-training-dataset         LLM: 7 prompt training dataset                   41MB  2023-11-15 07:32:56           1413        111  1.0              \n",
            "thedrcat/daigt-proper-train-dataset                    DAIGT Proper Train Dataset                      119MB  2023-11-05 14:03:25           1395        128  1.0              \n",
            "joebeachcapital/30000-spotify-songs                    30000 Spotify Songs                               3MB  2023-11-01 06:06:43           9140        200  1.0              \n",
            "mlippo/average-global-iq-per-country-with-other-stats  Average global IQ per country with other stats    6KB  2023-11-16 19:37:24           1316         28  1.0              \n",
            "ddosad/auto-sales-data                                 Automobile Sales data                            79KB  2023-11-18 12:36:41           3497         67  1.0              \n",
            "jacksondivakarr/laptop-price-prediction-dataset        Laptop Price Prediction Dataset                 119KB  2023-11-30 16:23:34            622         25  1.0              \n",
            "asimislam/30-yrs-stock-market-data                     30 yrs Stock Market Data                        882KB  2023-11-29 20:18:02           1029         26  1.0              \n",
            "abdallahwagih/house-price                              House Price                                     780KB  2023-11-24 13:36:42            563         26  1.0              \n",
            "everydaycodings/multi-platform-online-courses-dataset  Multi-Platform Online Courses Dataset             3MB  2023-11-26 08:11:49            714         24  1.0              \n",
            "imtkaggleteam/life-expectancy                          Life Expectancy                                 730KB  2023-11-30 12:22:23            549         33  0.9411765        \n",
            "nelgiriyewithana/world-educational-data                World Educational Data                            9KB  2023-11-04 06:10:17           7405        150  1.0              \n",
            "mahmoudshogaa/titanic-dataset                          titanic_dataset                                  22KB  2023-11-24 14:19:44           1003         41  1.0              \n",
            "maso0dahmed/netflix-movies-and-shows                   Netflix Movies and Shows                        172KB  2023-11-19 18:26:53           2550         45  1.0              \n",
            "prasad22/healthcare-dataset                            🩺Healthcare Dataset 🧪                           483KB  2023-10-31 11:30:58           6670        103  1.0              \n",
            "jacksondivakarr/online-shopping-dataset                🛒 Online Shopping Dataset 📊📉📈                     5MB  2023-11-12 12:35:58           3802         68  1.0              \n",
            "imtkaggleteam/obesity                                  Obesity                                           1MB  2023-11-30 12:57:26            354         37  0.9411765        \n",
            "nelgiriyewithana/australian-vehicle-prices             Australian Vehicle Prices                       582KB  2023-11-27 04:51:30            901         43  1.0              \n",
            "Downloading imaterialist-fashion-2019-FGVC6.zip to /content\n",
            "100% 19.1G/19.1G [16:51<00:00, 13.9MB/s]\n",
            "100% 19.1G/19.1G [16:51<00:00, 20.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.remove('imaterialist-fashion-2019-FGVC6.zip')"
      ],
      "metadata": {
        "id": "YMNxMzKVHj9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class REBNCONV(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=3, dirate=1):\n",
        "        super(REBNCONV, self).__init__()\n",
        "\n",
        "        self.conv_s1 = nn.Conv2d(\n",
        "            in_ch, out_ch, 3, padding=1 * dirate, dilation=1 * dirate\n",
        "        )\n",
        "        self.bn_s1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu_s1 = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "        xout = self.relu_s1(self.bn_s1(self.conv_s1(hx)))\n",
        "\n",
        "        return xout\n",
        "\n",
        "\n",
        "## upsample tensor 'src' to have the same spatial size with tensor 'tar'\n",
        "def _upsample_like(src, tar):\n",
        "\n",
        "    src = F.upsample(src, size=tar.shape[2:], mode=\"bilinear\")\n",
        "\n",
        "    return src\n",
        "\n",
        "\n",
        "### RSU-7 ###\n",
        "class RSU7(nn.Module):  # UNet07DRES(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU7, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool5 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv7 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv6d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv5d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "        hx = self.pool5(hx5)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx)\n",
        "\n",
        "        hx7 = self.rebnconv7(hx6)\n",
        "\n",
        "        hx6d = self.rebnconv6d(torch.cat((hx7, hx6), 1))\n",
        "        hx6dup = _upsample_like(hx6d, hx5)\n",
        "\n",
        "        hx5d = self.rebnconv5d(torch.cat((hx6dup, hx5), 1))\n",
        "        hx5dup = _upsample_like(hx5d, hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        \"\"\"\n",
        "        del hx1, hx2, hx3, hx4, hx5, hx6, hx7\n",
        "        del hx6d, hx5d, hx3d, hx2d\n",
        "        del hx2dup, hx3dup, hx4dup, hx5dup, hx6dup\n",
        "        \"\"\"\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "### RSU-6 ###\n",
        "class RSU6(nn.Module):  # UNet06DRES(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU6, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool4 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv6 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv5d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "        hx = self.pool4(hx4)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx)\n",
        "\n",
        "        hx6 = self.rebnconv6(hx5)\n",
        "\n",
        "        hx5d = self.rebnconv5d(torch.cat((hx6, hx5), 1))\n",
        "        hx5dup = _upsample_like(hx5d, hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5dup, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        \"\"\"\n",
        "        del hx1, hx2, hx3, hx4, hx5, hx6\n",
        "        del hx5d, hx4d, hx3d, hx2d\n",
        "        del hx2dup, hx3dup, hx4dup, hx5dup\n",
        "        \"\"\"\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "### RSU-5 ###\n",
        "class RSU5(nn.Module):  # UNet05DRES(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU5, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool3 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv5 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv4d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "        hx = self.pool3(hx3)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx)\n",
        "\n",
        "        hx5 = self.rebnconv5(hx4)\n",
        "\n",
        "        hx4d = self.rebnconv4d(torch.cat((hx5, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        \"\"\"\n",
        "        del hx1, hx2, hx3, hx4, hx5\n",
        "        del hx4d, hx3d, hx2d\n",
        "        del hx2dup, hx3dup, hx4dup\n",
        "        \"\"\"\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "### RSU-4 ###\n",
        "class RSU4(nn.Module):  # UNet04DRES(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.pool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "        self.pool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=1)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx = self.pool1(hx1)\n",
        "\n",
        "        hx2 = self.rebnconv2(hx)\n",
        "        hx = self.pool2(hx2)\n",
        "\n",
        "        hx3 = self.rebnconv3(hx)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        \"\"\"\n",
        "        del hx1, hx2, hx3, hx4\n",
        "        del hx3d, hx2d\n",
        "        del hx2dup, hx3dup\n",
        "        \"\"\"\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "### RSU-4F ###\n",
        "class RSU4F(nn.Module):  # UNet04FRES(nn.Module):\n",
        "    def __init__(self, in_ch=3, mid_ch=12, out_ch=3):\n",
        "        super(RSU4F, self).__init__()\n",
        "\n",
        "        self.rebnconvin = REBNCONV(in_ch, out_ch, dirate=1)\n",
        "\n",
        "        self.rebnconv1 = REBNCONV(out_ch, mid_ch, dirate=1)\n",
        "        self.rebnconv2 = REBNCONV(mid_ch, mid_ch, dirate=2)\n",
        "        self.rebnconv3 = REBNCONV(mid_ch, mid_ch, dirate=4)\n",
        "\n",
        "        self.rebnconv4 = REBNCONV(mid_ch, mid_ch, dirate=8)\n",
        "\n",
        "        self.rebnconv3d = REBNCONV(mid_ch * 2, mid_ch, dirate=4)\n",
        "        self.rebnconv2d = REBNCONV(mid_ch * 2, mid_ch, dirate=2)\n",
        "        self.rebnconv1d = REBNCONV(mid_ch * 2, out_ch, dirate=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        hxin = self.rebnconvin(hx)\n",
        "\n",
        "        hx1 = self.rebnconv1(hxin)\n",
        "        hx2 = self.rebnconv2(hx1)\n",
        "        hx3 = self.rebnconv3(hx2)\n",
        "\n",
        "        hx4 = self.rebnconv4(hx3)\n",
        "\n",
        "        hx3d = self.rebnconv3d(torch.cat((hx4, hx3), 1))\n",
        "        hx2d = self.rebnconv2d(torch.cat((hx3d, hx2), 1))\n",
        "        hx1d = self.rebnconv1d(torch.cat((hx2d, hx1), 1))\n",
        "\n",
        "        \"\"\"\n",
        "        del hx1, hx2, hx3, hx4\n",
        "        del hx3d, hx2d\n",
        "        \"\"\"\n",
        "\n",
        "        return hx1d + hxin\n",
        "\n",
        "\n",
        "##### U^2-Net ####\n",
        "class U2NET(nn.Module):\n",
        "    def __init__(self, in_ch=3, out_ch=1):\n",
        "        super(U2NET, self).__init__()\n",
        "\n",
        "        self.stage1 = RSU7(in_ch, 32, 64)\n",
        "        self.pool12 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage2 = RSU6(64, 32, 128)\n",
        "        self.pool23 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage3 = RSU5(128, 64, 256)\n",
        "        self.pool34 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage4 = RSU4(256, 128, 512)\n",
        "        self.pool45 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage5 = RSU4F(512, 256, 512)\n",
        "        self.pool56 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
        "\n",
        "        self.stage6 = RSU4F(512, 256, 512)\n",
        "\n",
        "        # decoder\n",
        "        self.stage5d = RSU4F(1024, 256, 512)\n",
        "        self.stage4d = RSU4(1024, 128, 256)\n",
        "        self.stage3d = RSU5(512, 64, 128)\n",
        "        self.stage2d = RSU6(256, 32, 64)\n",
        "        self.stage1d = RSU7(128, 16, 64)\n",
        "\n",
        "        self.side1 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
        "        self.side2 = nn.Conv2d(64, out_ch, 3, padding=1)\n",
        "        self.side3 = nn.Conv2d(128, out_ch, 3, padding=1)\n",
        "        self.side4 = nn.Conv2d(256, out_ch, 3, padding=1)\n",
        "        self.side5 = nn.Conv2d(512, out_ch, 3, padding=1)\n",
        "        self.side6 = nn.Conv2d(512, out_ch, 3, padding=1)\n",
        "\n",
        "        self.outconv = nn.Conv2d(6 * out_ch, out_ch, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        hx = x\n",
        "\n",
        "        # stage 1\n",
        "        hx1 = self.stage1(hx)\n",
        "        hx = self.pool12(hx1)\n",
        "\n",
        "        # stage 2\n",
        "        hx2 = self.stage2(hx)\n",
        "        hx = self.pool23(hx2)\n",
        "\n",
        "        # stage 3\n",
        "        hx3 = self.stage3(hx)\n",
        "        hx = self.pool34(hx3)\n",
        "\n",
        "        # stage 4\n",
        "        hx4 = self.stage4(hx)\n",
        "        hx = self.pool45(hx4)\n",
        "\n",
        "        # stage 5\n",
        "        hx5 = self.stage5(hx)\n",
        "        hx = self.pool56(hx5)\n",
        "\n",
        "        # stage 6\n",
        "        hx6 = self.stage6(hx)\n",
        "        hx6up = _upsample_like(hx6, hx5)\n",
        "\n",
        "        # -------------------- decoder --------------------\n",
        "        hx5d = self.stage5d(torch.cat((hx6up, hx5), 1))\n",
        "        hx5dup = _upsample_like(hx5d, hx4)\n",
        "\n",
        "        hx4d = self.stage4d(torch.cat((hx5dup, hx4), 1))\n",
        "        hx4dup = _upsample_like(hx4d, hx3)\n",
        "\n",
        "        hx3d = self.stage3d(torch.cat((hx4dup, hx3), 1))\n",
        "        hx3dup = _upsample_like(hx3d, hx2)\n",
        "\n",
        "        hx2d = self.stage2d(torch.cat((hx3dup, hx2), 1))\n",
        "        hx2dup = _upsample_like(hx2d, hx1)\n",
        "\n",
        "        hx1d = self.stage1d(torch.cat((hx2dup, hx1), 1))\n",
        "\n",
        "        # side output\n",
        "        d1 = self.side1(hx1d)\n",
        "\n",
        "        d2 = self.side2(hx2d)\n",
        "        d2 = _upsample_like(d2, d1)\n",
        "\n",
        "        d3 = self.side3(hx3d)\n",
        "        d3 = _upsample_like(d3, d1)\n",
        "\n",
        "        d4 = self.side4(hx4d)\n",
        "        d4 = _upsample_like(d4, d1)\n",
        "\n",
        "        d5 = self.side5(hx5d)\n",
        "        d5 = _upsample_like(d5, d1)\n",
        "\n",
        "        d6 = self.side6(hx6)\n",
        "        d6 = _upsample_like(d6, d1)\n",
        "\n",
        "        d0 = self.outconv(torch.cat((d1, d2, d3, d4, d5, d6), 1))\n",
        "\n",
        "        \"\"\"\n",
        "        del hx1, hx2, hx3, hx4, hx5, hx6\n",
        "        del hx5d, hx4d, hx3d, hx2d, hx1d\n",
        "        del hx6up, hx5dup, hx4dup, hx3dup, hx2dup\n",
        "        \"\"\"\n",
        "\n",
        "        return d0, d1, d2, d3, d4, d5, d6"
      ],
      "metadata": {
        "id": "XMH430SF_2fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import gdown\n",
        "import torch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "os.makedirs(\"prev_checkpoints\", exist_ok=True)\n",
        "gdown.download(\n",
        "    \"https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\",\n",
        "    \"./prev_checkpoints/u2net.pth\",\n",
        "    quiet=False,\n",
        ")\n",
        "\n",
        "def save_checkpoint(model, save_path):\n",
        "    print(save_path)\n",
        "    if not os.path.exists(os.path.dirname(save_path)):\n",
        "        os.makedirs(os.path.dirname(save_path))\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "u_net = U2NET(in_ch=3, out_ch=4)\n",
        "save_checkpoint(u_net, os.path.join(\"prev_checkpoints\", \"u2net_random.pth\"))\n",
        "\n",
        "# u2net.pth contains trained weights\n",
        "trained_net_pth = os.path.join(\"prev_checkpoints\", \"u2net.pth\")\n",
        "# u2net_random.pth contains random weights\n",
        "custom_net_pth = os.path.join(\"prev_checkpoints\", \"u2net_random.pth\")\n",
        "\n",
        "net_state_dict = torch.load(trained_net_pth)\n",
        "count = 0\n",
        "for k, v in net_state_dict.items():\n",
        "    count += 1\n",
        "print(\"Total number of layers in trained model are: {}\".format(count))\n",
        "\n",
        "custom_state_dict = torch.load(custom_net_pth)\n",
        "count = 0\n",
        "for k, v in custom_state_dict.items():\n",
        "    count += 1\n",
        "print(\"Total number of layers in trained model are: {}\".format(count))\n",
        "\n",
        "total_count = 0\n",
        "update_count = 0\n",
        "for k, v in net_state_dict.items():\n",
        "    total_count += 1\n",
        "    #name = k[7:]\n",
        "    if custom_state_dict[k].shape == v.shape:\n",
        "        update_count += 1\n",
        "        custom_state_dict[k] = v\n",
        "\n",
        "print(\n",
        "    \"Out of {} layers in custom network, {} layers weights are recovered from trained model\".format(\n",
        "        total_count, update_count\n",
        "    )\n",
        ")\n",
        "torch.save(\n",
        "    custom_state_dict, os.path.join(\"prev_checkpoints\", \"cloth_segm_unet_surgery.pth\")\n",
        ")\n",
        "print(\"cloth_segm_unet_surgery.pth is generated in prev_checkpoints directory!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4c2gfgOAOJL",
        "outputId": "203c14f3-a51f-4eeb-e509-c67520e34034"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ao1ovG1Qtx4b7EoskHXmi2E9rp5CHLcZ\n",
            "To: /content/prev_checkpoints/u2net.pth\n",
            "100%|██████████| 176M/176M [00:01<00:00, 159MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prev_checkpoints/u2net_random.pth\n",
            "Total number of layers in trained model are: 686\n",
            "Total number of layers in trained model are: 798\n",
            "Out of 686 layers in custom network, 672 layers weights are recovered from trained model\n",
            "cloth_segm_unet_surgery.pth is generated in prev_checkpoints directory!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print keys for the trained model\n",
        "print(\"Keys in trained model:\")\n",
        "print(list(net_state_dict.keys()))\n",
        "\n",
        "# Print keys for the randomly initialized model\n",
        "print(\"Keys in randomly initialized model:\")\n",
        "print(list(custom_state_dict.keys()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP00XPbZZaF5",
        "outputId": "6c203826-602a-48f2-cac7-d2dde55a68e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in trained model:\n",
            "['stage1.rebnconvin.conv_s1.weight', 'stage1.rebnconvin.conv_s1.bias', 'stage1.rebnconvin.bn_s1.weight', 'stage1.rebnconvin.bn_s1.bias', 'stage1.rebnconvin.bn_s1.running_mean', 'stage1.rebnconvin.bn_s1.running_var', 'stage1.rebnconv1.conv_s1.weight', 'stage1.rebnconv1.conv_s1.bias', 'stage1.rebnconv1.bn_s1.weight', 'stage1.rebnconv1.bn_s1.bias', 'stage1.rebnconv1.bn_s1.running_mean', 'stage1.rebnconv1.bn_s1.running_var', 'stage1.rebnconv2.conv_s1.weight', 'stage1.rebnconv2.conv_s1.bias', 'stage1.rebnconv2.bn_s1.weight', 'stage1.rebnconv2.bn_s1.bias', 'stage1.rebnconv2.bn_s1.running_mean', 'stage1.rebnconv2.bn_s1.running_var', 'stage1.rebnconv3.conv_s1.weight', 'stage1.rebnconv3.conv_s1.bias', 'stage1.rebnconv3.bn_s1.weight', 'stage1.rebnconv3.bn_s1.bias', 'stage1.rebnconv3.bn_s1.running_mean', 'stage1.rebnconv3.bn_s1.running_var', 'stage1.rebnconv4.conv_s1.weight', 'stage1.rebnconv4.conv_s1.bias', 'stage1.rebnconv4.bn_s1.weight', 'stage1.rebnconv4.bn_s1.bias', 'stage1.rebnconv4.bn_s1.running_mean', 'stage1.rebnconv4.bn_s1.running_var', 'stage1.rebnconv5.conv_s1.weight', 'stage1.rebnconv5.conv_s1.bias', 'stage1.rebnconv5.bn_s1.weight', 'stage1.rebnconv5.bn_s1.bias', 'stage1.rebnconv5.bn_s1.running_mean', 'stage1.rebnconv5.bn_s1.running_var', 'stage1.rebnconv6.conv_s1.weight', 'stage1.rebnconv6.conv_s1.bias', 'stage1.rebnconv6.bn_s1.weight', 'stage1.rebnconv6.bn_s1.bias', 'stage1.rebnconv6.bn_s1.running_mean', 'stage1.rebnconv6.bn_s1.running_var', 'stage1.rebnconv7.conv_s1.weight', 'stage1.rebnconv7.conv_s1.bias', 'stage1.rebnconv7.bn_s1.weight', 'stage1.rebnconv7.bn_s1.bias', 'stage1.rebnconv7.bn_s1.running_mean', 'stage1.rebnconv7.bn_s1.running_var', 'stage1.rebnconv6d.conv_s1.weight', 'stage1.rebnconv6d.conv_s1.bias', 'stage1.rebnconv6d.bn_s1.weight', 'stage1.rebnconv6d.bn_s1.bias', 'stage1.rebnconv6d.bn_s1.running_mean', 'stage1.rebnconv6d.bn_s1.running_var', 'stage1.rebnconv5d.conv_s1.weight', 'stage1.rebnconv5d.conv_s1.bias', 'stage1.rebnconv5d.bn_s1.weight', 'stage1.rebnconv5d.bn_s1.bias', 'stage1.rebnconv5d.bn_s1.running_mean', 'stage1.rebnconv5d.bn_s1.running_var', 'stage1.rebnconv4d.conv_s1.weight', 'stage1.rebnconv4d.conv_s1.bias', 'stage1.rebnconv4d.bn_s1.weight', 'stage1.rebnconv4d.bn_s1.bias', 'stage1.rebnconv4d.bn_s1.running_mean', 'stage1.rebnconv4d.bn_s1.running_var', 'stage1.rebnconv3d.conv_s1.weight', 'stage1.rebnconv3d.conv_s1.bias', 'stage1.rebnconv3d.bn_s1.weight', 'stage1.rebnconv3d.bn_s1.bias', 'stage1.rebnconv3d.bn_s1.running_mean', 'stage1.rebnconv3d.bn_s1.running_var', 'stage1.rebnconv2d.conv_s1.weight', 'stage1.rebnconv2d.conv_s1.bias', 'stage1.rebnconv2d.bn_s1.weight', 'stage1.rebnconv2d.bn_s1.bias', 'stage1.rebnconv2d.bn_s1.running_mean', 'stage1.rebnconv2d.bn_s1.running_var', 'stage1.rebnconv1d.conv_s1.weight', 'stage1.rebnconv1d.conv_s1.bias', 'stage1.rebnconv1d.bn_s1.weight', 'stage1.rebnconv1d.bn_s1.bias', 'stage1.rebnconv1d.bn_s1.running_mean', 'stage1.rebnconv1d.bn_s1.running_var', 'stage2.rebnconvin.conv_s1.weight', 'stage2.rebnconvin.conv_s1.bias', 'stage2.rebnconvin.bn_s1.weight', 'stage2.rebnconvin.bn_s1.bias', 'stage2.rebnconvin.bn_s1.running_mean', 'stage2.rebnconvin.bn_s1.running_var', 'stage2.rebnconv1.conv_s1.weight', 'stage2.rebnconv1.conv_s1.bias', 'stage2.rebnconv1.bn_s1.weight', 'stage2.rebnconv1.bn_s1.bias', 'stage2.rebnconv1.bn_s1.running_mean', 'stage2.rebnconv1.bn_s1.running_var', 'stage2.rebnconv2.conv_s1.weight', 'stage2.rebnconv2.conv_s1.bias', 'stage2.rebnconv2.bn_s1.weight', 'stage2.rebnconv2.bn_s1.bias', 'stage2.rebnconv2.bn_s1.running_mean', 'stage2.rebnconv2.bn_s1.running_var', 'stage2.rebnconv3.conv_s1.weight', 'stage2.rebnconv3.conv_s1.bias', 'stage2.rebnconv3.bn_s1.weight', 'stage2.rebnconv3.bn_s1.bias', 'stage2.rebnconv3.bn_s1.running_mean', 'stage2.rebnconv3.bn_s1.running_var', 'stage2.rebnconv4.conv_s1.weight', 'stage2.rebnconv4.conv_s1.bias', 'stage2.rebnconv4.bn_s1.weight', 'stage2.rebnconv4.bn_s1.bias', 'stage2.rebnconv4.bn_s1.running_mean', 'stage2.rebnconv4.bn_s1.running_var', 'stage2.rebnconv5.conv_s1.weight', 'stage2.rebnconv5.conv_s1.bias', 'stage2.rebnconv5.bn_s1.weight', 'stage2.rebnconv5.bn_s1.bias', 'stage2.rebnconv5.bn_s1.running_mean', 'stage2.rebnconv5.bn_s1.running_var', 'stage2.rebnconv6.conv_s1.weight', 'stage2.rebnconv6.conv_s1.bias', 'stage2.rebnconv6.bn_s1.weight', 'stage2.rebnconv6.bn_s1.bias', 'stage2.rebnconv6.bn_s1.running_mean', 'stage2.rebnconv6.bn_s1.running_var', 'stage2.rebnconv5d.conv_s1.weight', 'stage2.rebnconv5d.conv_s1.bias', 'stage2.rebnconv5d.bn_s1.weight', 'stage2.rebnconv5d.bn_s1.bias', 'stage2.rebnconv5d.bn_s1.running_mean', 'stage2.rebnconv5d.bn_s1.running_var', 'stage2.rebnconv4d.conv_s1.weight', 'stage2.rebnconv4d.conv_s1.bias', 'stage2.rebnconv4d.bn_s1.weight', 'stage2.rebnconv4d.bn_s1.bias', 'stage2.rebnconv4d.bn_s1.running_mean', 'stage2.rebnconv4d.bn_s1.running_var', 'stage2.rebnconv3d.conv_s1.weight', 'stage2.rebnconv3d.conv_s1.bias', 'stage2.rebnconv3d.bn_s1.weight', 'stage2.rebnconv3d.bn_s1.bias', 'stage2.rebnconv3d.bn_s1.running_mean', 'stage2.rebnconv3d.bn_s1.running_var', 'stage2.rebnconv2d.conv_s1.weight', 'stage2.rebnconv2d.conv_s1.bias', 'stage2.rebnconv2d.bn_s1.weight', 'stage2.rebnconv2d.bn_s1.bias', 'stage2.rebnconv2d.bn_s1.running_mean', 'stage2.rebnconv2d.bn_s1.running_var', 'stage2.rebnconv1d.conv_s1.weight', 'stage2.rebnconv1d.conv_s1.bias', 'stage2.rebnconv1d.bn_s1.weight', 'stage2.rebnconv1d.bn_s1.bias', 'stage2.rebnconv1d.bn_s1.running_mean', 'stage2.rebnconv1d.bn_s1.running_var', 'stage3.rebnconvin.conv_s1.weight', 'stage3.rebnconvin.conv_s1.bias', 'stage3.rebnconvin.bn_s1.weight', 'stage3.rebnconvin.bn_s1.bias', 'stage3.rebnconvin.bn_s1.running_mean', 'stage3.rebnconvin.bn_s1.running_var', 'stage3.rebnconv1.conv_s1.weight', 'stage3.rebnconv1.conv_s1.bias', 'stage3.rebnconv1.bn_s1.weight', 'stage3.rebnconv1.bn_s1.bias', 'stage3.rebnconv1.bn_s1.running_mean', 'stage3.rebnconv1.bn_s1.running_var', 'stage3.rebnconv2.conv_s1.weight', 'stage3.rebnconv2.conv_s1.bias', 'stage3.rebnconv2.bn_s1.weight', 'stage3.rebnconv2.bn_s1.bias', 'stage3.rebnconv2.bn_s1.running_mean', 'stage3.rebnconv2.bn_s1.running_var', 'stage3.rebnconv3.conv_s1.weight', 'stage3.rebnconv3.conv_s1.bias', 'stage3.rebnconv3.bn_s1.weight', 'stage3.rebnconv3.bn_s1.bias', 'stage3.rebnconv3.bn_s1.running_mean', 'stage3.rebnconv3.bn_s1.running_var', 'stage3.rebnconv4.conv_s1.weight', 'stage3.rebnconv4.conv_s1.bias', 'stage3.rebnconv4.bn_s1.weight', 'stage3.rebnconv4.bn_s1.bias', 'stage3.rebnconv4.bn_s1.running_mean', 'stage3.rebnconv4.bn_s1.running_var', 'stage3.rebnconv5.conv_s1.weight', 'stage3.rebnconv5.conv_s1.bias', 'stage3.rebnconv5.bn_s1.weight', 'stage3.rebnconv5.bn_s1.bias', 'stage3.rebnconv5.bn_s1.running_mean', 'stage3.rebnconv5.bn_s1.running_var', 'stage3.rebnconv4d.conv_s1.weight', 'stage3.rebnconv4d.conv_s1.bias', 'stage3.rebnconv4d.bn_s1.weight', 'stage3.rebnconv4d.bn_s1.bias', 'stage3.rebnconv4d.bn_s1.running_mean', 'stage3.rebnconv4d.bn_s1.running_var', 'stage3.rebnconv3d.conv_s1.weight', 'stage3.rebnconv3d.conv_s1.bias', 'stage3.rebnconv3d.bn_s1.weight', 'stage3.rebnconv3d.bn_s1.bias', 'stage3.rebnconv3d.bn_s1.running_mean', 'stage3.rebnconv3d.bn_s1.running_var', 'stage3.rebnconv2d.conv_s1.weight', 'stage3.rebnconv2d.conv_s1.bias', 'stage3.rebnconv2d.bn_s1.weight', 'stage3.rebnconv2d.bn_s1.bias', 'stage3.rebnconv2d.bn_s1.running_mean', 'stage3.rebnconv2d.bn_s1.running_var', 'stage3.rebnconv1d.conv_s1.weight', 'stage3.rebnconv1d.conv_s1.bias', 'stage3.rebnconv1d.bn_s1.weight', 'stage3.rebnconv1d.bn_s1.bias', 'stage3.rebnconv1d.bn_s1.running_mean', 'stage3.rebnconv1d.bn_s1.running_var', 'stage4.rebnconvin.conv_s1.weight', 'stage4.rebnconvin.conv_s1.bias', 'stage4.rebnconvin.bn_s1.weight', 'stage4.rebnconvin.bn_s1.bias', 'stage4.rebnconvin.bn_s1.running_mean', 'stage4.rebnconvin.bn_s1.running_var', 'stage4.rebnconv1.conv_s1.weight', 'stage4.rebnconv1.conv_s1.bias', 'stage4.rebnconv1.bn_s1.weight', 'stage4.rebnconv1.bn_s1.bias', 'stage4.rebnconv1.bn_s1.running_mean', 'stage4.rebnconv1.bn_s1.running_var', 'stage4.rebnconv2.conv_s1.weight', 'stage4.rebnconv2.conv_s1.bias', 'stage4.rebnconv2.bn_s1.weight', 'stage4.rebnconv2.bn_s1.bias', 'stage4.rebnconv2.bn_s1.running_mean', 'stage4.rebnconv2.bn_s1.running_var', 'stage4.rebnconv3.conv_s1.weight', 'stage4.rebnconv3.conv_s1.bias', 'stage4.rebnconv3.bn_s1.weight', 'stage4.rebnconv3.bn_s1.bias', 'stage4.rebnconv3.bn_s1.running_mean', 'stage4.rebnconv3.bn_s1.running_var', 'stage4.rebnconv4.conv_s1.weight', 'stage4.rebnconv4.conv_s1.bias', 'stage4.rebnconv4.bn_s1.weight', 'stage4.rebnconv4.bn_s1.bias', 'stage4.rebnconv4.bn_s1.running_mean', 'stage4.rebnconv4.bn_s1.running_var', 'stage4.rebnconv3d.conv_s1.weight', 'stage4.rebnconv3d.conv_s1.bias', 'stage4.rebnconv3d.bn_s1.weight', 'stage4.rebnconv3d.bn_s1.bias', 'stage4.rebnconv3d.bn_s1.running_mean', 'stage4.rebnconv3d.bn_s1.running_var', 'stage4.rebnconv2d.conv_s1.weight', 'stage4.rebnconv2d.conv_s1.bias', 'stage4.rebnconv2d.bn_s1.weight', 'stage4.rebnconv2d.bn_s1.bias', 'stage4.rebnconv2d.bn_s1.running_mean', 'stage4.rebnconv2d.bn_s1.running_var', 'stage4.rebnconv1d.conv_s1.weight', 'stage4.rebnconv1d.conv_s1.bias', 'stage4.rebnconv1d.bn_s1.weight', 'stage4.rebnconv1d.bn_s1.bias', 'stage4.rebnconv1d.bn_s1.running_mean', 'stage4.rebnconv1d.bn_s1.running_var', 'stage5.rebnconvin.conv_s1.weight', 'stage5.rebnconvin.conv_s1.bias', 'stage5.rebnconvin.bn_s1.weight', 'stage5.rebnconvin.bn_s1.bias', 'stage5.rebnconvin.bn_s1.running_mean', 'stage5.rebnconvin.bn_s1.running_var', 'stage5.rebnconv1.conv_s1.weight', 'stage5.rebnconv1.conv_s1.bias', 'stage5.rebnconv1.bn_s1.weight', 'stage5.rebnconv1.bn_s1.bias', 'stage5.rebnconv1.bn_s1.running_mean', 'stage5.rebnconv1.bn_s1.running_var', 'stage5.rebnconv2.conv_s1.weight', 'stage5.rebnconv2.conv_s1.bias', 'stage5.rebnconv2.bn_s1.weight', 'stage5.rebnconv2.bn_s1.bias', 'stage5.rebnconv2.bn_s1.running_mean', 'stage5.rebnconv2.bn_s1.running_var', 'stage5.rebnconv3.conv_s1.weight', 'stage5.rebnconv3.conv_s1.bias', 'stage5.rebnconv3.bn_s1.weight', 'stage5.rebnconv3.bn_s1.bias', 'stage5.rebnconv3.bn_s1.running_mean', 'stage5.rebnconv3.bn_s1.running_var', 'stage5.rebnconv4.conv_s1.weight', 'stage5.rebnconv4.conv_s1.bias', 'stage5.rebnconv4.bn_s1.weight', 'stage5.rebnconv4.bn_s1.bias', 'stage5.rebnconv4.bn_s1.running_mean', 'stage5.rebnconv4.bn_s1.running_var', 'stage5.rebnconv3d.conv_s1.weight', 'stage5.rebnconv3d.conv_s1.bias', 'stage5.rebnconv3d.bn_s1.weight', 'stage5.rebnconv3d.bn_s1.bias', 'stage5.rebnconv3d.bn_s1.running_mean', 'stage5.rebnconv3d.bn_s1.running_var', 'stage5.rebnconv2d.conv_s1.weight', 'stage5.rebnconv2d.conv_s1.bias', 'stage5.rebnconv2d.bn_s1.weight', 'stage5.rebnconv2d.bn_s1.bias', 'stage5.rebnconv2d.bn_s1.running_mean', 'stage5.rebnconv2d.bn_s1.running_var', 'stage5.rebnconv1d.conv_s1.weight', 'stage5.rebnconv1d.conv_s1.bias', 'stage5.rebnconv1d.bn_s1.weight', 'stage5.rebnconv1d.bn_s1.bias', 'stage5.rebnconv1d.bn_s1.running_mean', 'stage5.rebnconv1d.bn_s1.running_var', 'stage6.rebnconvin.conv_s1.weight', 'stage6.rebnconvin.conv_s1.bias', 'stage6.rebnconvin.bn_s1.weight', 'stage6.rebnconvin.bn_s1.bias', 'stage6.rebnconvin.bn_s1.running_mean', 'stage6.rebnconvin.bn_s1.running_var', 'stage6.rebnconv1.conv_s1.weight', 'stage6.rebnconv1.conv_s1.bias', 'stage6.rebnconv1.bn_s1.weight', 'stage6.rebnconv1.bn_s1.bias', 'stage6.rebnconv1.bn_s1.running_mean', 'stage6.rebnconv1.bn_s1.running_var', 'stage6.rebnconv2.conv_s1.weight', 'stage6.rebnconv2.conv_s1.bias', 'stage6.rebnconv2.bn_s1.weight', 'stage6.rebnconv2.bn_s1.bias', 'stage6.rebnconv2.bn_s1.running_mean', 'stage6.rebnconv2.bn_s1.running_var', 'stage6.rebnconv3.conv_s1.weight', 'stage6.rebnconv3.conv_s1.bias', 'stage6.rebnconv3.bn_s1.weight', 'stage6.rebnconv3.bn_s1.bias', 'stage6.rebnconv3.bn_s1.running_mean', 'stage6.rebnconv3.bn_s1.running_var', 'stage6.rebnconv4.conv_s1.weight', 'stage6.rebnconv4.conv_s1.bias', 'stage6.rebnconv4.bn_s1.weight', 'stage6.rebnconv4.bn_s1.bias', 'stage6.rebnconv4.bn_s1.running_mean', 'stage6.rebnconv4.bn_s1.running_var', 'stage6.rebnconv3d.conv_s1.weight', 'stage6.rebnconv3d.conv_s1.bias', 'stage6.rebnconv3d.bn_s1.weight', 'stage6.rebnconv3d.bn_s1.bias', 'stage6.rebnconv3d.bn_s1.running_mean', 'stage6.rebnconv3d.bn_s1.running_var', 'stage6.rebnconv2d.conv_s1.weight', 'stage6.rebnconv2d.conv_s1.bias', 'stage6.rebnconv2d.bn_s1.weight', 'stage6.rebnconv2d.bn_s1.bias', 'stage6.rebnconv2d.bn_s1.running_mean', 'stage6.rebnconv2d.bn_s1.running_var', 'stage6.rebnconv1d.conv_s1.weight', 'stage6.rebnconv1d.conv_s1.bias', 'stage6.rebnconv1d.bn_s1.weight', 'stage6.rebnconv1d.bn_s1.bias', 'stage6.rebnconv1d.bn_s1.running_mean', 'stage6.rebnconv1d.bn_s1.running_var', 'stage5d.rebnconvin.conv_s1.weight', 'stage5d.rebnconvin.conv_s1.bias', 'stage5d.rebnconvin.bn_s1.weight', 'stage5d.rebnconvin.bn_s1.bias', 'stage5d.rebnconvin.bn_s1.running_mean', 'stage5d.rebnconvin.bn_s1.running_var', 'stage5d.rebnconv1.conv_s1.weight', 'stage5d.rebnconv1.conv_s1.bias', 'stage5d.rebnconv1.bn_s1.weight', 'stage5d.rebnconv1.bn_s1.bias', 'stage5d.rebnconv1.bn_s1.running_mean', 'stage5d.rebnconv1.bn_s1.running_var', 'stage5d.rebnconv2.conv_s1.weight', 'stage5d.rebnconv2.conv_s1.bias', 'stage5d.rebnconv2.bn_s1.weight', 'stage5d.rebnconv2.bn_s1.bias', 'stage5d.rebnconv2.bn_s1.running_mean', 'stage5d.rebnconv2.bn_s1.running_var', 'stage5d.rebnconv3.conv_s1.weight', 'stage5d.rebnconv3.conv_s1.bias', 'stage5d.rebnconv3.bn_s1.weight', 'stage5d.rebnconv3.bn_s1.bias', 'stage5d.rebnconv3.bn_s1.running_mean', 'stage5d.rebnconv3.bn_s1.running_var', 'stage5d.rebnconv4.conv_s1.weight', 'stage5d.rebnconv4.conv_s1.bias', 'stage5d.rebnconv4.bn_s1.weight', 'stage5d.rebnconv4.bn_s1.bias', 'stage5d.rebnconv4.bn_s1.running_mean', 'stage5d.rebnconv4.bn_s1.running_var', 'stage5d.rebnconv3d.conv_s1.weight', 'stage5d.rebnconv3d.conv_s1.bias', 'stage5d.rebnconv3d.bn_s1.weight', 'stage5d.rebnconv3d.bn_s1.bias', 'stage5d.rebnconv3d.bn_s1.running_mean', 'stage5d.rebnconv3d.bn_s1.running_var', 'stage5d.rebnconv2d.conv_s1.weight', 'stage5d.rebnconv2d.conv_s1.bias', 'stage5d.rebnconv2d.bn_s1.weight', 'stage5d.rebnconv2d.bn_s1.bias', 'stage5d.rebnconv2d.bn_s1.running_mean', 'stage5d.rebnconv2d.bn_s1.running_var', 'stage5d.rebnconv1d.conv_s1.weight', 'stage5d.rebnconv1d.conv_s1.bias', 'stage5d.rebnconv1d.bn_s1.weight', 'stage5d.rebnconv1d.bn_s1.bias', 'stage5d.rebnconv1d.bn_s1.running_mean', 'stage5d.rebnconv1d.bn_s1.running_var', 'stage4d.rebnconvin.conv_s1.weight', 'stage4d.rebnconvin.conv_s1.bias', 'stage4d.rebnconvin.bn_s1.weight', 'stage4d.rebnconvin.bn_s1.bias', 'stage4d.rebnconvin.bn_s1.running_mean', 'stage4d.rebnconvin.bn_s1.running_var', 'stage4d.rebnconv1.conv_s1.weight', 'stage4d.rebnconv1.conv_s1.bias', 'stage4d.rebnconv1.bn_s1.weight', 'stage4d.rebnconv1.bn_s1.bias', 'stage4d.rebnconv1.bn_s1.running_mean', 'stage4d.rebnconv1.bn_s1.running_var', 'stage4d.rebnconv2.conv_s1.weight', 'stage4d.rebnconv2.conv_s1.bias', 'stage4d.rebnconv2.bn_s1.weight', 'stage4d.rebnconv2.bn_s1.bias', 'stage4d.rebnconv2.bn_s1.running_mean', 'stage4d.rebnconv2.bn_s1.running_var', 'stage4d.rebnconv3.conv_s1.weight', 'stage4d.rebnconv3.conv_s1.bias', 'stage4d.rebnconv3.bn_s1.weight', 'stage4d.rebnconv3.bn_s1.bias', 'stage4d.rebnconv3.bn_s1.running_mean', 'stage4d.rebnconv3.bn_s1.running_var', 'stage4d.rebnconv4.conv_s1.weight', 'stage4d.rebnconv4.conv_s1.bias', 'stage4d.rebnconv4.bn_s1.weight', 'stage4d.rebnconv4.bn_s1.bias', 'stage4d.rebnconv4.bn_s1.running_mean', 'stage4d.rebnconv4.bn_s1.running_var', 'stage4d.rebnconv3d.conv_s1.weight', 'stage4d.rebnconv3d.conv_s1.bias', 'stage4d.rebnconv3d.bn_s1.weight', 'stage4d.rebnconv3d.bn_s1.bias', 'stage4d.rebnconv3d.bn_s1.running_mean', 'stage4d.rebnconv3d.bn_s1.running_var', 'stage4d.rebnconv2d.conv_s1.weight', 'stage4d.rebnconv2d.conv_s1.bias', 'stage4d.rebnconv2d.bn_s1.weight', 'stage4d.rebnconv2d.bn_s1.bias', 'stage4d.rebnconv2d.bn_s1.running_mean', 'stage4d.rebnconv2d.bn_s1.running_var', 'stage4d.rebnconv1d.conv_s1.weight', 'stage4d.rebnconv1d.conv_s1.bias', 'stage4d.rebnconv1d.bn_s1.weight', 'stage4d.rebnconv1d.bn_s1.bias', 'stage4d.rebnconv1d.bn_s1.running_mean', 'stage4d.rebnconv1d.bn_s1.running_var', 'stage3d.rebnconvin.conv_s1.weight', 'stage3d.rebnconvin.conv_s1.bias', 'stage3d.rebnconvin.bn_s1.weight', 'stage3d.rebnconvin.bn_s1.bias', 'stage3d.rebnconvin.bn_s1.running_mean', 'stage3d.rebnconvin.bn_s1.running_var', 'stage3d.rebnconv1.conv_s1.weight', 'stage3d.rebnconv1.conv_s1.bias', 'stage3d.rebnconv1.bn_s1.weight', 'stage3d.rebnconv1.bn_s1.bias', 'stage3d.rebnconv1.bn_s1.running_mean', 'stage3d.rebnconv1.bn_s1.running_var', 'stage3d.rebnconv2.conv_s1.weight', 'stage3d.rebnconv2.conv_s1.bias', 'stage3d.rebnconv2.bn_s1.weight', 'stage3d.rebnconv2.bn_s1.bias', 'stage3d.rebnconv2.bn_s1.running_mean', 'stage3d.rebnconv2.bn_s1.running_var', 'stage3d.rebnconv3.conv_s1.weight', 'stage3d.rebnconv3.conv_s1.bias', 'stage3d.rebnconv3.bn_s1.weight', 'stage3d.rebnconv3.bn_s1.bias', 'stage3d.rebnconv3.bn_s1.running_mean', 'stage3d.rebnconv3.bn_s1.running_var', 'stage3d.rebnconv4.conv_s1.weight', 'stage3d.rebnconv4.conv_s1.bias', 'stage3d.rebnconv4.bn_s1.weight', 'stage3d.rebnconv4.bn_s1.bias', 'stage3d.rebnconv4.bn_s1.running_mean', 'stage3d.rebnconv4.bn_s1.running_var', 'stage3d.rebnconv5.conv_s1.weight', 'stage3d.rebnconv5.conv_s1.bias', 'stage3d.rebnconv5.bn_s1.weight', 'stage3d.rebnconv5.bn_s1.bias', 'stage3d.rebnconv5.bn_s1.running_mean', 'stage3d.rebnconv5.bn_s1.running_var', 'stage3d.rebnconv4d.conv_s1.weight', 'stage3d.rebnconv4d.conv_s1.bias', 'stage3d.rebnconv4d.bn_s1.weight', 'stage3d.rebnconv4d.bn_s1.bias', 'stage3d.rebnconv4d.bn_s1.running_mean', 'stage3d.rebnconv4d.bn_s1.running_var', 'stage3d.rebnconv3d.conv_s1.weight', 'stage3d.rebnconv3d.conv_s1.bias', 'stage3d.rebnconv3d.bn_s1.weight', 'stage3d.rebnconv3d.bn_s1.bias', 'stage3d.rebnconv3d.bn_s1.running_mean', 'stage3d.rebnconv3d.bn_s1.running_var', 'stage3d.rebnconv2d.conv_s1.weight', 'stage3d.rebnconv2d.conv_s1.bias', 'stage3d.rebnconv2d.bn_s1.weight', 'stage3d.rebnconv2d.bn_s1.bias', 'stage3d.rebnconv2d.bn_s1.running_mean', 'stage3d.rebnconv2d.bn_s1.running_var', 'stage3d.rebnconv1d.conv_s1.weight', 'stage3d.rebnconv1d.conv_s1.bias', 'stage3d.rebnconv1d.bn_s1.weight', 'stage3d.rebnconv1d.bn_s1.bias', 'stage3d.rebnconv1d.bn_s1.running_mean', 'stage3d.rebnconv1d.bn_s1.running_var', 'stage2d.rebnconvin.conv_s1.weight', 'stage2d.rebnconvin.conv_s1.bias', 'stage2d.rebnconvin.bn_s1.weight', 'stage2d.rebnconvin.bn_s1.bias', 'stage2d.rebnconvin.bn_s1.running_mean', 'stage2d.rebnconvin.bn_s1.running_var', 'stage2d.rebnconv1.conv_s1.weight', 'stage2d.rebnconv1.conv_s1.bias', 'stage2d.rebnconv1.bn_s1.weight', 'stage2d.rebnconv1.bn_s1.bias', 'stage2d.rebnconv1.bn_s1.running_mean', 'stage2d.rebnconv1.bn_s1.running_var', 'stage2d.rebnconv2.conv_s1.weight', 'stage2d.rebnconv2.conv_s1.bias', 'stage2d.rebnconv2.bn_s1.weight', 'stage2d.rebnconv2.bn_s1.bias', 'stage2d.rebnconv2.bn_s1.running_mean', 'stage2d.rebnconv2.bn_s1.running_var', 'stage2d.rebnconv3.conv_s1.weight', 'stage2d.rebnconv3.conv_s1.bias', 'stage2d.rebnconv3.bn_s1.weight', 'stage2d.rebnconv3.bn_s1.bias', 'stage2d.rebnconv3.bn_s1.running_mean', 'stage2d.rebnconv3.bn_s1.running_var', 'stage2d.rebnconv4.conv_s1.weight', 'stage2d.rebnconv4.conv_s1.bias', 'stage2d.rebnconv4.bn_s1.weight', 'stage2d.rebnconv4.bn_s1.bias', 'stage2d.rebnconv4.bn_s1.running_mean', 'stage2d.rebnconv4.bn_s1.running_var', 'stage2d.rebnconv5.conv_s1.weight', 'stage2d.rebnconv5.conv_s1.bias', 'stage2d.rebnconv5.bn_s1.weight', 'stage2d.rebnconv5.bn_s1.bias', 'stage2d.rebnconv5.bn_s1.running_mean', 'stage2d.rebnconv5.bn_s1.running_var', 'stage2d.rebnconv6.conv_s1.weight', 'stage2d.rebnconv6.conv_s1.bias', 'stage2d.rebnconv6.bn_s1.weight', 'stage2d.rebnconv6.bn_s1.bias', 'stage2d.rebnconv6.bn_s1.running_mean', 'stage2d.rebnconv6.bn_s1.running_var', 'stage2d.rebnconv5d.conv_s1.weight', 'stage2d.rebnconv5d.conv_s1.bias', 'stage2d.rebnconv5d.bn_s1.weight', 'stage2d.rebnconv5d.bn_s1.bias', 'stage2d.rebnconv5d.bn_s1.running_mean', 'stage2d.rebnconv5d.bn_s1.running_var', 'stage2d.rebnconv4d.conv_s1.weight', 'stage2d.rebnconv4d.conv_s1.bias', 'stage2d.rebnconv4d.bn_s1.weight', 'stage2d.rebnconv4d.bn_s1.bias', 'stage2d.rebnconv4d.bn_s1.running_mean', 'stage2d.rebnconv4d.bn_s1.running_var', 'stage2d.rebnconv3d.conv_s1.weight', 'stage2d.rebnconv3d.conv_s1.bias', 'stage2d.rebnconv3d.bn_s1.weight', 'stage2d.rebnconv3d.bn_s1.bias', 'stage2d.rebnconv3d.bn_s1.running_mean', 'stage2d.rebnconv3d.bn_s1.running_var', 'stage2d.rebnconv2d.conv_s1.weight', 'stage2d.rebnconv2d.conv_s1.bias', 'stage2d.rebnconv2d.bn_s1.weight', 'stage2d.rebnconv2d.bn_s1.bias', 'stage2d.rebnconv2d.bn_s1.running_mean', 'stage2d.rebnconv2d.bn_s1.running_var', 'stage2d.rebnconv1d.conv_s1.weight', 'stage2d.rebnconv1d.conv_s1.bias', 'stage2d.rebnconv1d.bn_s1.weight', 'stage2d.rebnconv1d.bn_s1.bias', 'stage2d.rebnconv1d.bn_s1.running_mean', 'stage2d.rebnconv1d.bn_s1.running_var', 'stage1d.rebnconvin.conv_s1.weight', 'stage1d.rebnconvin.conv_s1.bias', 'stage1d.rebnconvin.bn_s1.weight', 'stage1d.rebnconvin.bn_s1.bias', 'stage1d.rebnconvin.bn_s1.running_mean', 'stage1d.rebnconvin.bn_s1.running_var', 'stage1d.rebnconv1.conv_s1.weight', 'stage1d.rebnconv1.conv_s1.bias', 'stage1d.rebnconv1.bn_s1.weight', 'stage1d.rebnconv1.bn_s1.bias', 'stage1d.rebnconv1.bn_s1.running_mean', 'stage1d.rebnconv1.bn_s1.running_var', 'stage1d.rebnconv2.conv_s1.weight', 'stage1d.rebnconv2.conv_s1.bias', 'stage1d.rebnconv2.bn_s1.weight', 'stage1d.rebnconv2.bn_s1.bias', 'stage1d.rebnconv2.bn_s1.running_mean', 'stage1d.rebnconv2.bn_s1.running_var', 'stage1d.rebnconv3.conv_s1.weight', 'stage1d.rebnconv3.conv_s1.bias', 'stage1d.rebnconv3.bn_s1.weight', 'stage1d.rebnconv3.bn_s1.bias', 'stage1d.rebnconv3.bn_s1.running_mean', 'stage1d.rebnconv3.bn_s1.running_var', 'stage1d.rebnconv4.conv_s1.weight', 'stage1d.rebnconv4.conv_s1.bias', 'stage1d.rebnconv4.bn_s1.weight', 'stage1d.rebnconv4.bn_s1.bias', 'stage1d.rebnconv4.bn_s1.running_mean', 'stage1d.rebnconv4.bn_s1.running_var', 'stage1d.rebnconv5.conv_s1.weight', 'stage1d.rebnconv5.conv_s1.bias', 'stage1d.rebnconv5.bn_s1.weight', 'stage1d.rebnconv5.bn_s1.bias', 'stage1d.rebnconv5.bn_s1.running_mean', 'stage1d.rebnconv5.bn_s1.running_var', 'stage1d.rebnconv6.conv_s1.weight', 'stage1d.rebnconv6.conv_s1.bias', 'stage1d.rebnconv6.bn_s1.weight', 'stage1d.rebnconv6.bn_s1.bias', 'stage1d.rebnconv6.bn_s1.running_mean', 'stage1d.rebnconv6.bn_s1.running_var', 'stage1d.rebnconv7.conv_s1.weight', 'stage1d.rebnconv7.conv_s1.bias', 'stage1d.rebnconv7.bn_s1.weight', 'stage1d.rebnconv7.bn_s1.bias', 'stage1d.rebnconv7.bn_s1.running_mean', 'stage1d.rebnconv7.bn_s1.running_var', 'stage1d.rebnconv6d.conv_s1.weight', 'stage1d.rebnconv6d.conv_s1.bias', 'stage1d.rebnconv6d.bn_s1.weight', 'stage1d.rebnconv6d.bn_s1.bias', 'stage1d.rebnconv6d.bn_s1.running_mean', 'stage1d.rebnconv6d.bn_s1.running_var', 'stage1d.rebnconv5d.conv_s1.weight', 'stage1d.rebnconv5d.conv_s1.bias', 'stage1d.rebnconv5d.bn_s1.weight', 'stage1d.rebnconv5d.bn_s1.bias', 'stage1d.rebnconv5d.bn_s1.running_mean', 'stage1d.rebnconv5d.bn_s1.running_var', 'stage1d.rebnconv4d.conv_s1.weight', 'stage1d.rebnconv4d.conv_s1.bias', 'stage1d.rebnconv4d.bn_s1.weight', 'stage1d.rebnconv4d.bn_s1.bias', 'stage1d.rebnconv4d.bn_s1.running_mean', 'stage1d.rebnconv4d.bn_s1.running_var', 'stage1d.rebnconv3d.conv_s1.weight', 'stage1d.rebnconv3d.conv_s1.bias', 'stage1d.rebnconv3d.bn_s1.weight', 'stage1d.rebnconv3d.bn_s1.bias', 'stage1d.rebnconv3d.bn_s1.running_mean', 'stage1d.rebnconv3d.bn_s1.running_var', 'stage1d.rebnconv2d.conv_s1.weight', 'stage1d.rebnconv2d.conv_s1.bias', 'stage1d.rebnconv2d.bn_s1.weight', 'stage1d.rebnconv2d.bn_s1.bias', 'stage1d.rebnconv2d.bn_s1.running_mean', 'stage1d.rebnconv2d.bn_s1.running_var', 'stage1d.rebnconv1d.conv_s1.weight', 'stage1d.rebnconv1d.conv_s1.bias', 'stage1d.rebnconv1d.bn_s1.weight', 'stage1d.rebnconv1d.bn_s1.bias', 'stage1d.rebnconv1d.bn_s1.running_mean', 'stage1d.rebnconv1d.bn_s1.running_var', 'side1.weight', 'side1.bias', 'side2.weight', 'side2.bias', 'side3.weight', 'side3.bias', 'side4.weight', 'side4.bias', 'side5.weight', 'side5.bias', 'side6.weight', 'side6.bias', 'outconv.weight', 'outconv.bias']\n",
            "Keys in randomly initialized model:\n",
            "['stage1.rebnconvin.conv_s1.weight', 'stage1.rebnconvin.conv_s1.bias', 'stage1.rebnconvin.bn_s1.weight', 'stage1.rebnconvin.bn_s1.bias', 'stage1.rebnconvin.bn_s1.running_mean', 'stage1.rebnconvin.bn_s1.running_var', 'stage1.rebnconvin.bn_s1.num_batches_tracked', 'stage1.rebnconv1.conv_s1.weight', 'stage1.rebnconv1.conv_s1.bias', 'stage1.rebnconv1.bn_s1.weight', 'stage1.rebnconv1.bn_s1.bias', 'stage1.rebnconv1.bn_s1.running_mean', 'stage1.rebnconv1.bn_s1.running_var', 'stage1.rebnconv1.bn_s1.num_batches_tracked', 'stage1.rebnconv2.conv_s1.weight', 'stage1.rebnconv2.conv_s1.bias', 'stage1.rebnconv2.bn_s1.weight', 'stage1.rebnconv2.bn_s1.bias', 'stage1.rebnconv2.bn_s1.running_mean', 'stage1.rebnconv2.bn_s1.running_var', 'stage1.rebnconv2.bn_s1.num_batches_tracked', 'stage1.rebnconv3.conv_s1.weight', 'stage1.rebnconv3.conv_s1.bias', 'stage1.rebnconv3.bn_s1.weight', 'stage1.rebnconv3.bn_s1.bias', 'stage1.rebnconv3.bn_s1.running_mean', 'stage1.rebnconv3.bn_s1.running_var', 'stage1.rebnconv3.bn_s1.num_batches_tracked', 'stage1.rebnconv4.conv_s1.weight', 'stage1.rebnconv4.conv_s1.bias', 'stage1.rebnconv4.bn_s1.weight', 'stage1.rebnconv4.bn_s1.bias', 'stage1.rebnconv4.bn_s1.running_mean', 'stage1.rebnconv4.bn_s1.running_var', 'stage1.rebnconv4.bn_s1.num_batches_tracked', 'stage1.rebnconv5.conv_s1.weight', 'stage1.rebnconv5.conv_s1.bias', 'stage1.rebnconv5.bn_s1.weight', 'stage1.rebnconv5.bn_s1.bias', 'stage1.rebnconv5.bn_s1.running_mean', 'stage1.rebnconv5.bn_s1.running_var', 'stage1.rebnconv5.bn_s1.num_batches_tracked', 'stage1.rebnconv6.conv_s1.weight', 'stage1.rebnconv6.conv_s1.bias', 'stage1.rebnconv6.bn_s1.weight', 'stage1.rebnconv6.bn_s1.bias', 'stage1.rebnconv6.bn_s1.running_mean', 'stage1.rebnconv6.bn_s1.running_var', 'stage1.rebnconv6.bn_s1.num_batches_tracked', 'stage1.rebnconv7.conv_s1.weight', 'stage1.rebnconv7.conv_s1.bias', 'stage1.rebnconv7.bn_s1.weight', 'stage1.rebnconv7.bn_s1.bias', 'stage1.rebnconv7.bn_s1.running_mean', 'stage1.rebnconv7.bn_s1.running_var', 'stage1.rebnconv7.bn_s1.num_batches_tracked', 'stage1.rebnconv6d.conv_s1.weight', 'stage1.rebnconv6d.conv_s1.bias', 'stage1.rebnconv6d.bn_s1.weight', 'stage1.rebnconv6d.bn_s1.bias', 'stage1.rebnconv6d.bn_s1.running_mean', 'stage1.rebnconv6d.bn_s1.running_var', 'stage1.rebnconv6d.bn_s1.num_batches_tracked', 'stage1.rebnconv5d.conv_s1.weight', 'stage1.rebnconv5d.conv_s1.bias', 'stage1.rebnconv5d.bn_s1.weight', 'stage1.rebnconv5d.bn_s1.bias', 'stage1.rebnconv5d.bn_s1.running_mean', 'stage1.rebnconv5d.bn_s1.running_var', 'stage1.rebnconv5d.bn_s1.num_batches_tracked', 'stage1.rebnconv4d.conv_s1.weight', 'stage1.rebnconv4d.conv_s1.bias', 'stage1.rebnconv4d.bn_s1.weight', 'stage1.rebnconv4d.bn_s1.bias', 'stage1.rebnconv4d.bn_s1.running_mean', 'stage1.rebnconv4d.bn_s1.running_var', 'stage1.rebnconv4d.bn_s1.num_batches_tracked', 'stage1.rebnconv3d.conv_s1.weight', 'stage1.rebnconv3d.conv_s1.bias', 'stage1.rebnconv3d.bn_s1.weight', 'stage1.rebnconv3d.bn_s1.bias', 'stage1.rebnconv3d.bn_s1.running_mean', 'stage1.rebnconv3d.bn_s1.running_var', 'stage1.rebnconv3d.bn_s1.num_batches_tracked', 'stage1.rebnconv2d.conv_s1.weight', 'stage1.rebnconv2d.conv_s1.bias', 'stage1.rebnconv2d.bn_s1.weight', 'stage1.rebnconv2d.bn_s1.bias', 'stage1.rebnconv2d.bn_s1.running_mean', 'stage1.rebnconv2d.bn_s1.running_var', 'stage1.rebnconv2d.bn_s1.num_batches_tracked', 'stage1.rebnconv1d.conv_s1.weight', 'stage1.rebnconv1d.conv_s1.bias', 'stage1.rebnconv1d.bn_s1.weight', 'stage1.rebnconv1d.bn_s1.bias', 'stage1.rebnconv1d.bn_s1.running_mean', 'stage1.rebnconv1d.bn_s1.running_var', 'stage1.rebnconv1d.bn_s1.num_batches_tracked', 'stage2.rebnconvin.conv_s1.weight', 'stage2.rebnconvin.conv_s1.bias', 'stage2.rebnconvin.bn_s1.weight', 'stage2.rebnconvin.bn_s1.bias', 'stage2.rebnconvin.bn_s1.running_mean', 'stage2.rebnconvin.bn_s1.running_var', 'stage2.rebnconvin.bn_s1.num_batches_tracked', 'stage2.rebnconv1.conv_s1.weight', 'stage2.rebnconv1.conv_s1.bias', 'stage2.rebnconv1.bn_s1.weight', 'stage2.rebnconv1.bn_s1.bias', 'stage2.rebnconv1.bn_s1.running_mean', 'stage2.rebnconv1.bn_s1.running_var', 'stage2.rebnconv1.bn_s1.num_batches_tracked', 'stage2.rebnconv2.conv_s1.weight', 'stage2.rebnconv2.conv_s1.bias', 'stage2.rebnconv2.bn_s1.weight', 'stage2.rebnconv2.bn_s1.bias', 'stage2.rebnconv2.bn_s1.running_mean', 'stage2.rebnconv2.bn_s1.running_var', 'stage2.rebnconv2.bn_s1.num_batches_tracked', 'stage2.rebnconv3.conv_s1.weight', 'stage2.rebnconv3.conv_s1.bias', 'stage2.rebnconv3.bn_s1.weight', 'stage2.rebnconv3.bn_s1.bias', 'stage2.rebnconv3.bn_s1.running_mean', 'stage2.rebnconv3.bn_s1.running_var', 'stage2.rebnconv3.bn_s1.num_batches_tracked', 'stage2.rebnconv4.conv_s1.weight', 'stage2.rebnconv4.conv_s1.bias', 'stage2.rebnconv4.bn_s1.weight', 'stage2.rebnconv4.bn_s1.bias', 'stage2.rebnconv4.bn_s1.running_mean', 'stage2.rebnconv4.bn_s1.running_var', 'stage2.rebnconv4.bn_s1.num_batches_tracked', 'stage2.rebnconv5.conv_s1.weight', 'stage2.rebnconv5.conv_s1.bias', 'stage2.rebnconv5.bn_s1.weight', 'stage2.rebnconv5.bn_s1.bias', 'stage2.rebnconv5.bn_s1.running_mean', 'stage2.rebnconv5.bn_s1.running_var', 'stage2.rebnconv5.bn_s1.num_batches_tracked', 'stage2.rebnconv6.conv_s1.weight', 'stage2.rebnconv6.conv_s1.bias', 'stage2.rebnconv6.bn_s1.weight', 'stage2.rebnconv6.bn_s1.bias', 'stage2.rebnconv6.bn_s1.running_mean', 'stage2.rebnconv6.bn_s1.running_var', 'stage2.rebnconv6.bn_s1.num_batches_tracked', 'stage2.rebnconv5d.conv_s1.weight', 'stage2.rebnconv5d.conv_s1.bias', 'stage2.rebnconv5d.bn_s1.weight', 'stage2.rebnconv5d.bn_s1.bias', 'stage2.rebnconv5d.bn_s1.running_mean', 'stage2.rebnconv5d.bn_s1.running_var', 'stage2.rebnconv5d.bn_s1.num_batches_tracked', 'stage2.rebnconv4d.conv_s1.weight', 'stage2.rebnconv4d.conv_s1.bias', 'stage2.rebnconv4d.bn_s1.weight', 'stage2.rebnconv4d.bn_s1.bias', 'stage2.rebnconv4d.bn_s1.running_mean', 'stage2.rebnconv4d.bn_s1.running_var', 'stage2.rebnconv4d.bn_s1.num_batches_tracked', 'stage2.rebnconv3d.conv_s1.weight', 'stage2.rebnconv3d.conv_s1.bias', 'stage2.rebnconv3d.bn_s1.weight', 'stage2.rebnconv3d.bn_s1.bias', 'stage2.rebnconv3d.bn_s1.running_mean', 'stage2.rebnconv3d.bn_s1.running_var', 'stage2.rebnconv3d.bn_s1.num_batches_tracked', 'stage2.rebnconv2d.conv_s1.weight', 'stage2.rebnconv2d.conv_s1.bias', 'stage2.rebnconv2d.bn_s1.weight', 'stage2.rebnconv2d.bn_s1.bias', 'stage2.rebnconv2d.bn_s1.running_mean', 'stage2.rebnconv2d.bn_s1.running_var', 'stage2.rebnconv2d.bn_s1.num_batches_tracked', 'stage2.rebnconv1d.conv_s1.weight', 'stage2.rebnconv1d.conv_s1.bias', 'stage2.rebnconv1d.bn_s1.weight', 'stage2.rebnconv1d.bn_s1.bias', 'stage2.rebnconv1d.bn_s1.running_mean', 'stage2.rebnconv1d.bn_s1.running_var', 'stage2.rebnconv1d.bn_s1.num_batches_tracked', 'stage3.rebnconvin.conv_s1.weight', 'stage3.rebnconvin.conv_s1.bias', 'stage3.rebnconvin.bn_s1.weight', 'stage3.rebnconvin.bn_s1.bias', 'stage3.rebnconvin.bn_s1.running_mean', 'stage3.rebnconvin.bn_s1.running_var', 'stage3.rebnconvin.bn_s1.num_batches_tracked', 'stage3.rebnconv1.conv_s1.weight', 'stage3.rebnconv1.conv_s1.bias', 'stage3.rebnconv1.bn_s1.weight', 'stage3.rebnconv1.bn_s1.bias', 'stage3.rebnconv1.bn_s1.running_mean', 'stage3.rebnconv1.bn_s1.running_var', 'stage3.rebnconv1.bn_s1.num_batches_tracked', 'stage3.rebnconv2.conv_s1.weight', 'stage3.rebnconv2.conv_s1.bias', 'stage3.rebnconv2.bn_s1.weight', 'stage3.rebnconv2.bn_s1.bias', 'stage3.rebnconv2.bn_s1.running_mean', 'stage3.rebnconv2.bn_s1.running_var', 'stage3.rebnconv2.bn_s1.num_batches_tracked', 'stage3.rebnconv3.conv_s1.weight', 'stage3.rebnconv3.conv_s1.bias', 'stage3.rebnconv3.bn_s1.weight', 'stage3.rebnconv3.bn_s1.bias', 'stage3.rebnconv3.bn_s1.running_mean', 'stage3.rebnconv3.bn_s1.running_var', 'stage3.rebnconv3.bn_s1.num_batches_tracked', 'stage3.rebnconv4.conv_s1.weight', 'stage3.rebnconv4.conv_s1.bias', 'stage3.rebnconv4.bn_s1.weight', 'stage3.rebnconv4.bn_s1.bias', 'stage3.rebnconv4.bn_s1.running_mean', 'stage3.rebnconv4.bn_s1.running_var', 'stage3.rebnconv4.bn_s1.num_batches_tracked', 'stage3.rebnconv5.conv_s1.weight', 'stage3.rebnconv5.conv_s1.bias', 'stage3.rebnconv5.bn_s1.weight', 'stage3.rebnconv5.bn_s1.bias', 'stage3.rebnconv5.bn_s1.running_mean', 'stage3.rebnconv5.bn_s1.running_var', 'stage3.rebnconv5.bn_s1.num_batches_tracked', 'stage3.rebnconv4d.conv_s1.weight', 'stage3.rebnconv4d.conv_s1.bias', 'stage3.rebnconv4d.bn_s1.weight', 'stage3.rebnconv4d.bn_s1.bias', 'stage3.rebnconv4d.bn_s1.running_mean', 'stage3.rebnconv4d.bn_s1.running_var', 'stage3.rebnconv4d.bn_s1.num_batches_tracked', 'stage3.rebnconv3d.conv_s1.weight', 'stage3.rebnconv3d.conv_s1.bias', 'stage3.rebnconv3d.bn_s1.weight', 'stage3.rebnconv3d.bn_s1.bias', 'stage3.rebnconv3d.bn_s1.running_mean', 'stage3.rebnconv3d.bn_s1.running_var', 'stage3.rebnconv3d.bn_s1.num_batches_tracked', 'stage3.rebnconv2d.conv_s1.weight', 'stage3.rebnconv2d.conv_s1.bias', 'stage3.rebnconv2d.bn_s1.weight', 'stage3.rebnconv2d.bn_s1.bias', 'stage3.rebnconv2d.bn_s1.running_mean', 'stage3.rebnconv2d.bn_s1.running_var', 'stage3.rebnconv2d.bn_s1.num_batches_tracked', 'stage3.rebnconv1d.conv_s1.weight', 'stage3.rebnconv1d.conv_s1.bias', 'stage3.rebnconv1d.bn_s1.weight', 'stage3.rebnconv1d.bn_s1.bias', 'stage3.rebnconv1d.bn_s1.running_mean', 'stage3.rebnconv1d.bn_s1.running_var', 'stage3.rebnconv1d.bn_s1.num_batches_tracked', 'stage4.rebnconvin.conv_s1.weight', 'stage4.rebnconvin.conv_s1.bias', 'stage4.rebnconvin.bn_s1.weight', 'stage4.rebnconvin.bn_s1.bias', 'stage4.rebnconvin.bn_s1.running_mean', 'stage4.rebnconvin.bn_s1.running_var', 'stage4.rebnconvin.bn_s1.num_batches_tracked', 'stage4.rebnconv1.conv_s1.weight', 'stage4.rebnconv1.conv_s1.bias', 'stage4.rebnconv1.bn_s1.weight', 'stage4.rebnconv1.bn_s1.bias', 'stage4.rebnconv1.bn_s1.running_mean', 'stage4.rebnconv1.bn_s1.running_var', 'stage4.rebnconv1.bn_s1.num_batches_tracked', 'stage4.rebnconv2.conv_s1.weight', 'stage4.rebnconv2.conv_s1.bias', 'stage4.rebnconv2.bn_s1.weight', 'stage4.rebnconv2.bn_s1.bias', 'stage4.rebnconv2.bn_s1.running_mean', 'stage4.rebnconv2.bn_s1.running_var', 'stage4.rebnconv2.bn_s1.num_batches_tracked', 'stage4.rebnconv3.conv_s1.weight', 'stage4.rebnconv3.conv_s1.bias', 'stage4.rebnconv3.bn_s1.weight', 'stage4.rebnconv3.bn_s1.bias', 'stage4.rebnconv3.bn_s1.running_mean', 'stage4.rebnconv3.bn_s1.running_var', 'stage4.rebnconv3.bn_s1.num_batches_tracked', 'stage4.rebnconv4.conv_s1.weight', 'stage4.rebnconv4.conv_s1.bias', 'stage4.rebnconv4.bn_s1.weight', 'stage4.rebnconv4.bn_s1.bias', 'stage4.rebnconv4.bn_s1.running_mean', 'stage4.rebnconv4.bn_s1.running_var', 'stage4.rebnconv4.bn_s1.num_batches_tracked', 'stage4.rebnconv3d.conv_s1.weight', 'stage4.rebnconv3d.conv_s1.bias', 'stage4.rebnconv3d.bn_s1.weight', 'stage4.rebnconv3d.bn_s1.bias', 'stage4.rebnconv3d.bn_s1.running_mean', 'stage4.rebnconv3d.bn_s1.running_var', 'stage4.rebnconv3d.bn_s1.num_batches_tracked', 'stage4.rebnconv2d.conv_s1.weight', 'stage4.rebnconv2d.conv_s1.bias', 'stage4.rebnconv2d.bn_s1.weight', 'stage4.rebnconv2d.bn_s1.bias', 'stage4.rebnconv2d.bn_s1.running_mean', 'stage4.rebnconv2d.bn_s1.running_var', 'stage4.rebnconv2d.bn_s1.num_batches_tracked', 'stage4.rebnconv1d.conv_s1.weight', 'stage4.rebnconv1d.conv_s1.bias', 'stage4.rebnconv1d.bn_s1.weight', 'stage4.rebnconv1d.bn_s1.bias', 'stage4.rebnconv1d.bn_s1.running_mean', 'stage4.rebnconv1d.bn_s1.running_var', 'stage4.rebnconv1d.bn_s1.num_batches_tracked', 'stage5.rebnconvin.conv_s1.weight', 'stage5.rebnconvin.conv_s1.bias', 'stage5.rebnconvin.bn_s1.weight', 'stage5.rebnconvin.bn_s1.bias', 'stage5.rebnconvin.bn_s1.running_mean', 'stage5.rebnconvin.bn_s1.running_var', 'stage5.rebnconvin.bn_s1.num_batches_tracked', 'stage5.rebnconv1.conv_s1.weight', 'stage5.rebnconv1.conv_s1.bias', 'stage5.rebnconv1.bn_s1.weight', 'stage5.rebnconv1.bn_s1.bias', 'stage5.rebnconv1.bn_s1.running_mean', 'stage5.rebnconv1.bn_s1.running_var', 'stage5.rebnconv1.bn_s1.num_batches_tracked', 'stage5.rebnconv2.conv_s1.weight', 'stage5.rebnconv2.conv_s1.bias', 'stage5.rebnconv2.bn_s1.weight', 'stage5.rebnconv2.bn_s1.bias', 'stage5.rebnconv2.bn_s1.running_mean', 'stage5.rebnconv2.bn_s1.running_var', 'stage5.rebnconv2.bn_s1.num_batches_tracked', 'stage5.rebnconv3.conv_s1.weight', 'stage5.rebnconv3.conv_s1.bias', 'stage5.rebnconv3.bn_s1.weight', 'stage5.rebnconv3.bn_s1.bias', 'stage5.rebnconv3.bn_s1.running_mean', 'stage5.rebnconv3.bn_s1.running_var', 'stage5.rebnconv3.bn_s1.num_batches_tracked', 'stage5.rebnconv4.conv_s1.weight', 'stage5.rebnconv4.conv_s1.bias', 'stage5.rebnconv4.bn_s1.weight', 'stage5.rebnconv4.bn_s1.bias', 'stage5.rebnconv4.bn_s1.running_mean', 'stage5.rebnconv4.bn_s1.running_var', 'stage5.rebnconv4.bn_s1.num_batches_tracked', 'stage5.rebnconv3d.conv_s1.weight', 'stage5.rebnconv3d.conv_s1.bias', 'stage5.rebnconv3d.bn_s1.weight', 'stage5.rebnconv3d.bn_s1.bias', 'stage5.rebnconv3d.bn_s1.running_mean', 'stage5.rebnconv3d.bn_s1.running_var', 'stage5.rebnconv3d.bn_s1.num_batches_tracked', 'stage5.rebnconv2d.conv_s1.weight', 'stage5.rebnconv2d.conv_s1.bias', 'stage5.rebnconv2d.bn_s1.weight', 'stage5.rebnconv2d.bn_s1.bias', 'stage5.rebnconv2d.bn_s1.running_mean', 'stage5.rebnconv2d.bn_s1.running_var', 'stage5.rebnconv2d.bn_s1.num_batches_tracked', 'stage5.rebnconv1d.conv_s1.weight', 'stage5.rebnconv1d.conv_s1.bias', 'stage5.rebnconv1d.bn_s1.weight', 'stage5.rebnconv1d.bn_s1.bias', 'stage5.rebnconv1d.bn_s1.running_mean', 'stage5.rebnconv1d.bn_s1.running_var', 'stage5.rebnconv1d.bn_s1.num_batches_tracked', 'stage6.rebnconvin.conv_s1.weight', 'stage6.rebnconvin.conv_s1.bias', 'stage6.rebnconvin.bn_s1.weight', 'stage6.rebnconvin.bn_s1.bias', 'stage6.rebnconvin.bn_s1.running_mean', 'stage6.rebnconvin.bn_s1.running_var', 'stage6.rebnconvin.bn_s1.num_batches_tracked', 'stage6.rebnconv1.conv_s1.weight', 'stage6.rebnconv1.conv_s1.bias', 'stage6.rebnconv1.bn_s1.weight', 'stage6.rebnconv1.bn_s1.bias', 'stage6.rebnconv1.bn_s1.running_mean', 'stage6.rebnconv1.bn_s1.running_var', 'stage6.rebnconv1.bn_s1.num_batches_tracked', 'stage6.rebnconv2.conv_s1.weight', 'stage6.rebnconv2.conv_s1.bias', 'stage6.rebnconv2.bn_s1.weight', 'stage6.rebnconv2.bn_s1.bias', 'stage6.rebnconv2.bn_s1.running_mean', 'stage6.rebnconv2.bn_s1.running_var', 'stage6.rebnconv2.bn_s1.num_batches_tracked', 'stage6.rebnconv3.conv_s1.weight', 'stage6.rebnconv3.conv_s1.bias', 'stage6.rebnconv3.bn_s1.weight', 'stage6.rebnconv3.bn_s1.bias', 'stage6.rebnconv3.bn_s1.running_mean', 'stage6.rebnconv3.bn_s1.running_var', 'stage6.rebnconv3.bn_s1.num_batches_tracked', 'stage6.rebnconv4.conv_s1.weight', 'stage6.rebnconv4.conv_s1.bias', 'stage6.rebnconv4.bn_s1.weight', 'stage6.rebnconv4.bn_s1.bias', 'stage6.rebnconv4.bn_s1.running_mean', 'stage6.rebnconv4.bn_s1.running_var', 'stage6.rebnconv4.bn_s1.num_batches_tracked', 'stage6.rebnconv3d.conv_s1.weight', 'stage6.rebnconv3d.conv_s1.bias', 'stage6.rebnconv3d.bn_s1.weight', 'stage6.rebnconv3d.bn_s1.bias', 'stage6.rebnconv3d.bn_s1.running_mean', 'stage6.rebnconv3d.bn_s1.running_var', 'stage6.rebnconv3d.bn_s1.num_batches_tracked', 'stage6.rebnconv2d.conv_s1.weight', 'stage6.rebnconv2d.conv_s1.bias', 'stage6.rebnconv2d.bn_s1.weight', 'stage6.rebnconv2d.bn_s1.bias', 'stage6.rebnconv2d.bn_s1.running_mean', 'stage6.rebnconv2d.bn_s1.running_var', 'stage6.rebnconv2d.bn_s1.num_batches_tracked', 'stage6.rebnconv1d.conv_s1.weight', 'stage6.rebnconv1d.conv_s1.bias', 'stage6.rebnconv1d.bn_s1.weight', 'stage6.rebnconv1d.bn_s1.bias', 'stage6.rebnconv1d.bn_s1.running_mean', 'stage6.rebnconv1d.bn_s1.running_var', 'stage6.rebnconv1d.bn_s1.num_batches_tracked', 'stage5d.rebnconvin.conv_s1.weight', 'stage5d.rebnconvin.conv_s1.bias', 'stage5d.rebnconvin.bn_s1.weight', 'stage5d.rebnconvin.bn_s1.bias', 'stage5d.rebnconvin.bn_s1.running_mean', 'stage5d.rebnconvin.bn_s1.running_var', 'stage5d.rebnconvin.bn_s1.num_batches_tracked', 'stage5d.rebnconv1.conv_s1.weight', 'stage5d.rebnconv1.conv_s1.bias', 'stage5d.rebnconv1.bn_s1.weight', 'stage5d.rebnconv1.bn_s1.bias', 'stage5d.rebnconv1.bn_s1.running_mean', 'stage5d.rebnconv1.bn_s1.running_var', 'stage5d.rebnconv1.bn_s1.num_batches_tracked', 'stage5d.rebnconv2.conv_s1.weight', 'stage5d.rebnconv2.conv_s1.bias', 'stage5d.rebnconv2.bn_s1.weight', 'stage5d.rebnconv2.bn_s1.bias', 'stage5d.rebnconv2.bn_s1.running_mean', 'stage5d.rebnconv2.bn_s1.running_var', 'stage5d.rebnconv2.bn_s1.num_batches_tracked', 'stage5d.rebnconv3.conv_s1.weight', 'stage5d.rebnconv3.conv_s1.bias', 'stage5d.rebnconv3.bn_s1.weight', 'stage5d.rebnconv3.bn_s1.bias', 'stage5d.rebnconv3.bn_s1.running_mean', 'stage5d.rebnconv3.bn_s1.running_var', 'stage5d.rebnconv3.bn_s1.num_batches_tracked', 'stage5d.rebnconv4.conv_s1.weight', 'stage5d.rebnconv4.conv_s1.bias', 'stage5d.rebnconv4.bn_s1.weight', 'stage5d.rebnconv4.bn_s1.bias', 'stage5d.rebnconv4.bn_s1.running_mean', 'stage5d.rebnconv4.bn_s1.running_var', 'stage5d.rebnconv4.bn_s1.num_batches_tracked', 'stage5d.rebnconv3d.conv_s1.weight', 'stage5d.rebnconv3d.conv_s1.bias', 'stage5d.rebnconv3d.bn_s1.weight', 'stage5d.rebnconv3d.bn_s1.bias', 'stage5d.rebnconv3d.bn_s1.running_mean', 'stage5d.rebnconv3d.bn_s1.running_var', 'stage5d.rebnconv3d.bn_s1.num_batches_tracked', 'stage5d.rebnconv2d.conv_s1.weight', 'stage5d.rebnconv2d.conv_s1.bias', 'stage5d.rebnconv2d.bn_s1.weight', 'stage5d.rebnconv2d.bn_s1.bias', 'stage5d.rebnconv2d.bn_s1.running_mean', 'stage5d.rebnconv2d.bn_s1.running_var', 'stage5d.rebnconv2d.bn_s1.num_batches_tracked', 'stage5d.rebnconv1d.conv_s1.weight', 'stage5d.rebnconv1d.conv_s1.bias', 'stage5d.rebnconv1d.bn_s1.weight', 'stage5d.rebnconv1d.bn_s1.bias', 'stage5d.rebnconv1d.bn_s1.running_mean', 'stage5d.rebnconv1d.bn_s1.running_var', 'stage5d.rebnconv1d.bn_s1.num_batches_tracked', 'stage4d.rebnconvin.conv_s1.weight', 'stage4d.rebnconvin.conv_s1.bias', 'stage4d.rebnconvin.bn_s1.weight', 'stage4d.rebnconvin.bn_s1.bias', 'stage4d.rebnconvin.bn_s1.running_mean', 'stage4d.rebnconvin.bn_s1.running_var', 'stage4d.rebnconvin.bn_s1.num_batches_tracked', 'stage4d.rebnconv1.conv_s1.weight', 'stage4d.rebnconv1.conv_s1.bias', 'stage4d.rebnconv1.bn_s1.weight', 'stage4d.rebnconv1.bn_s1.bias', 'stage4d.rebnconv1.bn_s1.running_mean', 'stage4d.rebnconv1.bn_s1.running_var', 'stage4d.rebnconv1.bn_s1.num_batches_tracked', 'stage4d.rebnconv2.conv_s1.weight', 'stage4d.rebnconv2.conv_s1.bias', 'stage4d.rebnconv2.bn_s1.weight', 'stage4d.rebnconv2.bn_s1.bias', 'stage4d.rebnconv2.bn_s1.running_mean', 'stage4d.rebnconv2.bn_s1.running_var', 'stage4d.rebnconv2.bn_s1.num_batches_tracked', 'stage4d.rebnconv3.conv_s1.weight', 'stage4d.rebnconv3.conv_s1.bias', 'stage4d.rebnconv3.bn_s1.weight', 'stage4d.rebnconv3.bn_s1.bias', 'stage4d.rebnconv3.bn_s1.running_mean', 'stage4d.rebnconv3.bn_s1.running_var', 'stage4d.rebnconv3.bn_s1.num_batches_tracked', 'stage4d.rebnconv4.conv_s1.weight', 'stage4d.rebnconv4.conv_s1.bias', 'stage4d.rebnconv4.bn_s1.weight', 'stage4d.rebnconv4.bn_s1.bias', 'stage4d.rebnconv4.bn_s1.running_mean', 'stage4d.rebnconv4.bn_s1.running_var', 'stage4d.rebnconv4.bn_s1.num_batches_tracked', 'stage4d.rebnconv3d.conv_s1.weight', 'stage4d.rebnconv3d.conv_s1.bias', 'stage4d.rebnconv3d.bn_s1.weight', 'stage4d.rebnconv3d.bn_s1.bias', 'stage4d.rebnconv3d.bn_s1.running_mean', 'stage4d.rebnconv3d.bn_s1.running_var', 'stage4d.rebnconv3d.bn_s1.num_batches_tracked', 'stage4d.rebnconv2d.conv_s1.weight', 'stage4d.rebnconv2d.conv_s1.bias', 'stage4d.rebnconv2d.bn_s1.weight', 'stage4d.rebnconv2d.bn_s1.bias', 'stage4d.rebnconv2d.bn_s1.running_mean', 'stage4d.rebnconv2d.bn_s1.running_var', 'stage4d.rebnconv2d.bn_s1.num_batches_tracked', 'stage4d.rebnconv1d.conv_s1.weight', 'stage4d.rebnconv1d.conv_s1.bias', 'stage4d.rebnconv1d.bn_s1.weight', 'stage4d.rebnconv1d.bn_s1.bias', 'stage4d.rebnconv1d.bn_s1.running_mean', 'stage4d.rebnconv1d.bn_s1.running_var', 'stage4d.rebnconv1d.bn_s1.num_batches_tracked', 'stage3d.rebnconvin.conv_s1.weight', 'stage3d.rebnconvin.conv_s1.bias', 'stage3d.rebnconvin.bn_s1.weight', 'stage3d.rebnconvin.bn_s1.bias', 'stage3d.rebnconvin.bn_s1.running_mean', 'stage3d.rebnconvin.bn_s1.running_var', 'stage3d.rebnconvin.bn_s1.num_batches_tracked', 'stage3d.rebnconv1.conv_s1.weight', 'stage3d.rebnconv1.conv_s1.bias', 'stage3d.rebnconv1.bn_s1.weight', 'stage3d.rebnconv1.bn_s1.bias', 'stage3d.rebnconv1.bn_s1.running_mean', 'stage3d.rebnconv1.bn_s1.running_var', 'stage3d.rebnconv1.bn_s1.num_batches_tracked', 'stage3d.rebnconv2.conv_s1.weight', 'stage3d.rebnconv2.conv_s1.bias', 'stage3d.rebnconv2.bn_s1.weight', 'stage3d.rebnconv2.bn_s1.bias', 'stage3d.rebnconv2.bn_s1.running_mean', 'stage3d.rebnconv2.bn_s1.running_var', 'stage3d.rebnconv2.bn_s1.num_batches_tracked', 'stage3d.rebnconv3.conv_s1.weight', 'stage3d.rebnconv3.conv_s1.bias', 'stage3d.rebnconv3.bn_s1.weight', 'stage3d.rebnconv3.bn_s1.bias', 'stage3d.rebnconv3.bn_s1.running_mean', 'stage3d.rebnconv3.bn_s1.running_var', 'stage3d.rebnconv3.bn_s1.num_batches_tracked', 'stage3d.rebnconv4.conv_s1.weight', 'stage3d.rebnconv4.conv_s1.bias', 'stage3d.rebnconv4.bn_s1.weight', 'stage3d.rebnconv4.bn_s1.bias', 'stage3d.rebnconv4.bn_s1.running_mean', 'stage3d.rebnconv4.bn_s1.running_var', 'stage3d.rebnconv4.bn_s1.num_batches_tracked', 'stage3d.rebnconv5.conv_s1.weight', 'stage3d.rebnconv5.conv_s1.bias', 'stage3d.rebnconv5.bn_s1.weight', 'stage3d.rebnconv5.bn_s1.bias', 'stage3d.rebnconv5.bn_s1.running_mean', 'stage3d.rebnconv5.bn_s1.running_var', 'stage3d.rebnconv5.bn_s1.num_batches_tracked', 'stage3d.rebnconv4d.conv_s1.weight', 'stage3d.rebnconv4d.conv_s1.bias', 'stage3d.rebnconv4d.bn_s1.weight', 'stage3d.rebnconv4d.bn_s1.bias', 'stage3d.rebnconv4d.bn_s1.running_mean', 'stage3d.rebnconv4d.bn_s1.running_var', 'stage3d.rebnconv4d.bn_s1.num_batches_tracked', 'stage3d.rebnconv3d.conv_s1.weight', 'stage3d.rebnconv3d.conv_s1.bias', 'stage3d.rebnconv3d.bn_s1.weight', 'stage3d.rebnconv3d.bn_s1.bias', 'stage3d.rebnconv3d.bn_s1.running_mean', 'stage3d.rebnconv3d.bn_s1.running_var', 'stage3d.rebnconv3d.bn_s1.num_batches_tracked', 'stage3d.rebnconv2d.conv_s1.weight', 'stage3d.rebnconv2d.conv_s1.bias', 'stage3d.rebnconv2d.bn_s1.weight', 'stage3d.rebnconv2d.bn_s1.bias', 'stage3d.rebnconv2d.bn_s1.running_mean', 'stage3d.rebnconv2d.bn_s1.running_var', 'stage3d.rebnconv2d.bn_s1.num_batches_tracked', 'stage3d.rebnconv1d.conv_s1.weight', 'stage3d.rebnconv1d.conv_s1.bias', 'stage3d.rebnconv1d.bn_s1.weight', 'stage3d.rebnconv1d.bn_s1.bias', 'stage3d.rebnconv1d.bn_s1.running_mean', 'stage3d.rebnconv1d.bn_s1.running_var', 'stage3d.rebnconv1d.bn_s1.num_batches_tracked', 'stage2d.rebnconvin.conv_s1.weight', 'stage2d.rebnconvin.conv_s1.bias', 'stage2d.rebnconvin.bn_s1.weight', 'stage2d.rebnconvin.bn_s1.bias', 'stage2d.rebnconvin.bn_s1.running_mean', 'stage2d.rebnconvin.bn_s1.running_var', 'stage2d.rebnconvin.bn_s1.num_batches_tracked', 'stage2d.rebnconv1.conv_s1.weight', 'stage2d.rebnconv1.conv_s1.bias', 'stage2d.rebnconv1.bn_s1.weight', 'stage2d.rebnconv1.bn_s1.bias', 'stage2d.rebnconv1.bn_s1.running_mean', 'stage2d.rebnconv1.bn_s1.running_var', 'stage2d.rebnconv1.bn_s1.num_batches_tracked', 'stage2d.rebnconv2.conv_s1.weight', 'stage2d.rebnconv2.conv_s1.bias', 'stage2d.rebnconv2.bn_s1.weight', 'stage2d.rebnconv2.bn_s1.bias', 'stage2d.rebnconv2.bn_s1.running_mean', 'stage2d.rebnconv2.bn_s1.running_var', 'stage2d.rebnconv2.bn_s1.num_batches_tracked', 'stage2d.rebnconv3.conv_s1.weight', 'stage2d.rebnconv3.conv_s1.bias', 'stage2d.rebnconv3.bn_s1.weight', 'stage2d.rebnconv3.bn_s1.bias', 'stage2d.rebnconv3.bn_s1.running_mean', 'stage2d.rebnconv3.bn_s1.running_var', 'stage2d.rebnconv3.bn_s1.num_batches_tracked', 'stage2d.rebnconv4.conv_s1.weight', 'stage2d.rebnconv4.conv_s1.bias', 'stage2d.rebnconv4.bn_s1.weight', 'stage2d.rebnconv4.bn_s1.bias', 'stage2d.rebnconv4.bn_s1.running_mean', 'stage2d.rebnconv4.bn_s1.running_var', 'stage2d.rebnconv4.bn_s1.num_batches_tracked', 'stage2d.rebnconv5.conv_s1.weight', 'stage2d.rebnconv5.conv_s1.bias', 'stage2d.rebnconv5.bn_s1.weight', 'stage2d.rebnconv5.bn_s1.bias', 'stage2d.rebnconv5.bn_s1.running_mean', 'stage2d.rebnconv5.bn_s1.running_var', 'stage2d.rebnconv5.bn_s1.num_batches_tracked', 'stage2d.rebnconv6.conv_s1.weight', 'stage2d.rebnconv6.conv_s1.bias', 'stage2d.rebnconv6.bn_s1.weight', 'stage2d.rebnconv6.bn_s1.bias', 'stage2d.rebnconv6.bn_s1.running_mean', 'stage2d.rebnconv6.bn_s1.running_var', 'stage2d.rebnconv6.bn_s1.num_batches_tracked', 'stage2d.rebnconv5d.conv_s1.weight', 'stage2d.rebnconv5d.conv_s1.bias', 'stage2d.rebnconv5d.bn_s1.weight', 'stage2d.rebnconv5d.bn_s1.bias', 'stage2d.rebnconv5d.bn_s1.running_mean', 'stage2d.rebnconv5d.bn_s1.running_var', 'stage2d.rebnconv5d.bn_s1.num_batches_tracked', 'stage2d.rebnconv4d.conv_s1.weight', 'stage2d.rebnconv4d.conv_s1.bias', 'stage2d.rebnconv4d.bn_s1.weight', 'stage2d.rebnconv4d.bn_s1.bias', 'stage2d.rebnconv4d.bn_s1.running_mean', 'stage2d.rebnconv4d.bn_s1.running_var', 'stage2d.rebnconv4d.bn_s1.num_batches_tracked', 'stage2d.rebnconv3d.conv_s1.weight', 'stage2d.rebnconv3d.conv_s1.bias', 'stage2d.rebnconv3d.bn_s1.weight', 'stage2d.rebnconv3d.bn_s1.bias', 'stage2d.rebnconv3d.bn_s1.running_mean', 'stage2d.rebnconv3d.bn_s1.running_var', 'stage2d.rebnconv3d.bn_s1.num_batches_tracked', 'stage2d.rebnconv2d.conv_s1.weight', 'stage2d.rebnconv2d.conv_s1.bias', 'stage2d.rebnconv2d.bn_s1.weight', 'stage2d.rebnconv2d.bn_s1.bias', 'stage2d.rebnconv2d.bn_s1.running_mean', 'stage2d.rebnconv2d.bn_s1.running_var', 'stage2d.rebnconv2d.bn_s1.num_batches_tracked', 'stage2d.rebnconv1d.conv_s1.weight', 'stage2d.rebnconv1d.conv_s1.bias', 'stage2d.rebnconv1d.bn_s1.weight', 'stage2d.rebnconv1d.bn_s1.bias', 'stage2d.rebnconv1d.bn_s1.running_mean', 'stage2d.rebnconv1d.bn_s1.running_var', 'stage2d.rebnconv1d.bn_s1.num_batches_tracked', 'stage1d.rebnconvin.conv_s1.weight', 'stage1d.rebnconvin.conv_s1.bias', 'stage1d.rebnconvin.bn_s1.weight', 'stage1d.rebnconvin.bn_s1.bias', 'stage1d.rebnconvin.bn_s1.running_mean', 'stage1d.rebnconvin.bn_s1.running_var', 'stage1d.rebnconvin.bn_s1.num_batches_tracked', 'stage1d.rebnconv1.conv_s1.weight', 'stage1d.rebnconv1.conv_s1.bias', 'stage1d.rebnconv1.bn_s1.weight', 'stage1d.rebnconv1.bn_s1.bias', 'stage1d.rebnconv1.bn_s1.running_mean', 'stage1d.rebnconv1.bn_s1.running_var', 'stage1d.rebnconv1.bn_s1.num_batches_tracked', 'stage1d.rebnconv2.conv_s1.weight', 'stage1d.rebnconv2.conv_s1.bias', 'stage1d.rebnconv2.bn_s1.weight', 'stage1d.rebnconv2.bn_s1.bias', 'stage1d.rebnconv2.bn_s1.running_mean', 'stage1d.rebnconv2.bn_s1.running_var', 'stage1d.rebnconv2.bn_s1.num_batches_tracked', 'stage1d.rebnconv3.conv_s1.weight', 'stage1d.rebnconv3.conv_s1.bias', 'stage1d.rebnconv3.bn_s1.weight', 'stage1d.rebnconv3.bn_s1.bias', 'stage1d.rebnconv3.bn_s1.running_mean', 'stage1d.rebnconv3.bn_s1.running_var', 'stage1d.rebnconv3.bn_s1.num_batches_tracked', 'stage1d.rebnconv4.conv_s1.weight', 'stage1d.rebnconv4.conv_s1.bias', 'stage1d.rebnconv4.bn_s1.weight', 'stage1d.rebnconv4.bn_s1.bias', 'stage1d.rebnconv4.bn_s1.running_mean', 'stage1d.rebnconv4.bn_s1.running_var', 'stage1d.rebnconv4.bn_s1.num_batches_tracked', 'stage1d.rebnconv5.conv_s1.weight', 'stage1d.rebnconv5.conv_s1.bias', 'stage1d.rebnconv5.bn_s1.weight', 'stage1d.rebnconv5.bn_s1.bias', 'stage1d.rebnconv5.bn_s1.running_mean', 'stage1d.rebnconv5.bn_s1.running_var', 'stage1d.rebnconv5.bn_s1.num_batches_tracked', 'stage1d.rebnconv6.conv_s1.weight', 'stage1d.rebnconv6.conv_s1.bias', 'stage1d.rebnconv6.bn_s1.weight', 'stage1d.rebnconv6.bn_s1.bias', 'stage1d.rebnconv6.bn_s1.running_mean', 'stage1d.rebnconv6.bn_s1.running_var', 'stage1d.rebnconv6.bn_s1.num_batches_tracked', 'stage1d.rebnconv7.conv_s1.weight', 'stage1d.rebnconv7.conv_s1.bias', 'stage1d.rebnconv7.bn_s1.weight', 'stage1d.rebnconv7.bn_s1.bias', 'stage1d.rebnconv7.bn_s1.running_mean', 'stage1d.rebnconv7.bn_s1.running_var', 'stage1d.rebnconv7.bn_s1.num_batches_tracked', 'stage1d.rebnconv6d.conv_s1.weight', 'stage1d.rebnconv6d.conv_s1.bias', 'stage1d.rebnconv6d.bn_s1.weight', 'stage1d.rebnconv6d.bn_s1.bias', 'stage1d.rebnconv6d.bn_s1.running_mean', 'stage1d.rebnconv6d.bn_s1.running_var', 'stage1d.rebnconv6d.bn_s1.num_batches_tracked', 'stage1d.rebnconv5d.conv_s1.weight', 'stage1d.rebnconv5d.conv_s1.bias', 'stage1d.rebnconv5d.bn_s1.weight', 'stage1d.rebnconv5d.bn_s1.bias', 'stage1d.rebnconv5d.bn_s1.running_mean', 'stage1d.rebnconv5d.bn_s1.running_var', 'stage1d.rebnconv5d.bn_s1.num_batches_tracked', 'stage1d.rebnconv4d.conv_s1.weight', 'stage1d.rebnconv4d.conv_s1.bias', 'stage1d.rebnconv4d.bn_s1.weight', 'stage1d.rebnconv4d.bn_s1.bias', 'stage1d.rebnconv4d.bn_s1.running_mean', 'stage1d.rebnconv4d.bn_s1.running_var', 'stage1d.rebnconv4d.bn_s1.num_batches_tracked', 'stage1d.rebnconv3d.conv_s1.weight', 'stage1d.rebnconv3d.conv_s1.bias', 'stage1d.rebnconv3d.bn_s1.weight', 'stage1d.rebnconv3d.bn_s1.bias', 'stage1d.rebnconv3d.bn_s1.running_mean', 'stage1d.rebnconv3d.bn_s1.running_var', 'stage1d.rebnconv3d.bn_s1.num_batches_tracked', 'stage1d.rebnconv2d.conv_s1.weight', 'stage1d.rebnconv2d.conv_s1.bias', 'stage1d.rebnconv2d.bn_s1.weight', 'stage1d.rebnconv2d.bn_s1.bias', 'stage1d.rebnconv2d.bn_s1.running_mean', 'stage1d.rebnconv2d.bn_s1.running_var', 'stage1d.rebnconv2d.bn_s1.num_batches_tracked', 'stage1d.rebnconv1d.conv_s1.weight', 'stage1d.rebnconv1d.conv_s1.bias', 'stage1d.rebnconv1d.bn_s1.weight', 'stage1d.rebnconv1d.bn_s1.bias', 'stage1d.rebnconv1d.bn_s1.running_mean', 'stage1d.rebnconv1d.bn_s1.running_var', 'stage1d.rebnconv1d.bn_s1.num_batches_tracked', 'side1.weight', 'side1.bias', 'side2.weight', 'side2.bias', 'side3.weight', 'side3.bias', 'side4.weight', 'side4.bias', 'side5.weight', 'side5.bias', 'side6.weight', 'side6.bias', 'outconv.weight', 'outconv.bias']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import copy\n",
        "import cv2\n",
        "import numpy as np\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "\n",
        "\n",
        "def load_checkpoint(model, checkpoint_path):\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(\"----No checkpoints at given path----\")\n",
        "        return\n",
        "    model.load_state_dict(torch.load(checkpoint_path, map_location=torch.device(\"cpu\")))\n",
        "    print(\"----checkpoints loaded from path: {}----\".format(checkpoint_path))\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_checkpoint_mgpu(model, checkpoint_path):\n",
        "    if not os.path.exists(checkpoint_path):\n",
        "        print(\"----No checkpoints at given path----\")\n",
        "        return\n",
        "    model_state_dict = torch.load(checkpoint_path, map_location=torch.device(\"cpu\"))\n",
        "    new_state_dict = OrderedDict()\n",
        "    for k, v in model_state_dict.items():\n",
        "        name = k[7:]  # remove `module.`\n",
        "        new_state_dict[name] = v\n",
        "\n",
        "    model.load_state_dict(new_state_dict)\n",
        "    print(\"----checkpoints loaded from path: {}----\".format(checkpoint_path))\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_checkpoint(model, save_path):\n",
        "    print(save_path)\n",
        "    if not os.path.exists(os.path.dirname(save_path)):\n",
        "        os.makedirs(os.path.dirname(save_path))\n",
        "    torch.save(model.state_dict(), save_path)\n",
        "\n",
        "\n",
        "def save_checkpoints(opt, itr, net):\n",
        "    save_checkpoint(\n",
        "        net,\n",
        "        os.path.join(opt.save_dir, \"checkpoints\", \"itr_{:08d}_u2net.pth\".format(itr)),\n",
        "    )\n",
        "\n",
        "#-----------------\n",
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import random\n",
        "import pickle\n",
        "import torch\n",
        "from torch import distributed as dist\n",
        "from torch.utils.data.sampler import Sampler\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "\n",
        "def synchronize():\n",
        "    if not dist.is_available():\n",
        "        return\n",
        "\n",
        "    if not dist.is_initialized():\n",
        "        return\n",
        "\n",
        "    world_size = dist.get_world_size()\n",
        "    if world_size == 1:\n",
        "        return\n",
        "\n",
        "    dist.barrier()\n",
        "\n",
        "\n",
        "def cleanup(distributed):\n",
        "    if distributed:\n",
        "        dist.destroy_process_group()\n",
        "\n",
        "\n",
        "def get_world_size():\n",
        "    if not dist.is_available():\n",
        "        return 1\n",
        "\n",
        "    if not dist.is_initialized():\n",
        "        return 1\n",
        "\n",
        "    return dist.get_world_size()\n",
        "#-----------------\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Adding image in tensorboardX\n",
        "\n",
        "\n",
        "def tensor_for_board(img_tensor):\n",
        "    # map into [0,1]\n",
        "    tensor = (img_tensor.clone()+1) * 0.5\n",
        "    tensor.cpu().clamp(0, 1)\n",
        "\n",
        "    if tensor.size(1) == 1:\n",
        "        tensor = tensor.repeat(1, 3, 1, 1)\n",
        "\n",
        "    return tensor\n",
        "\n",
        "\n",
        "def tensor_list_for_board(img_tensors_list):\n",
        "    grid_h = len(img_tensors_list)\n",
        "    grid_w = max(len(img_tensors) for img_tensors in img_tensors_list)\n",
        "\n",
        "    batch_size, channel, height, width = tensor_for_board(\n",
        "        img_tensors_list[0][0]).size()\n",
        "    canvas_h = grid_h * height\n",
        "    canvas_w = grid_w * width\n",
        "    canvas = torch.FloatTensor(\n",
        "        batch_size, channel, canvas_h, canvas_w).fill_(0.5)\n",
        "    for i, img_tensors in enumerate(img_tensors_list):\n",
        "        for j, img_tensor in enumerate(img_tensors):\n",
        "            offset_h = i * height\n",
        "            offset_w = j * width\n",
        "            tensor = tensor_for_board(img_tensor)\n",
        "            canvas[:, :, offset_h: offset_h + height,\n",
        "                   offset_w: offset_w + width].copy_(tensor)\n",
        "\n",
        "    return canvas\n",
        "\n",
        "\n",
        "def board_add_image(board, tag_name, img_tensor, step_count):\n",
        "    tensor = tensor_for_board(img_tensor)\n",
        "\n",
        "    for i, img in enumerate(tensor):\n",
        "        board.add_image('%s/%03d' % (tag_name, i), img, step_count)\n",
        "\n",
        "\n",
        "def board_add_images(board, tag_name, img_tensors_list, step_count):\n",
        "    tensor = tensor_list_for_board(img_tensors_list)\n",
        "\n",
        "    for i, img in enumerate(tensor):\n",
        "        board.add_image('%s/%03d' % (tag_name, i), img, step_count)"
      ],
      "metadata": {
        "id": "3iufcu1GI1F1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path as osp\n",
        "import os\n",
        "\n",
        "\n",
        "class parser(object):\n",
        "    def __init__(self):\n",
        "        self.name = \"training_cloth_segm_u2net_exp1\"  # Expriment name\n",
        "        self.image_folder = \"/content/dataset/train/\"  # image folder path\n",
        "        self.df_path = \"/content/dataset/train.csv\"  # label csv path\n",
        "        self.distributed = False  # True for multi gpu training\n",
        "        self.isTrain = True\n",
        "\n",
        "        self.fine_width = 192 * 4\n",
        "        self.fine_height = 192 * 4\n",
        "\n",
        "        # Mean std params\n",
        "        self.mean = 0.5\n",
        "        self.std = 0.5\n",
        "\n",
        "        self.batchSize = 2  # 12\n",
        "        self.nThreads = 2  # 3\n",
        "        self.max_dataset_size = float(\"inf\")\n",
        "\n",
        "        self.serial_batches = False\n",
        "        self.continue_train = True\n",
        "        if self.continue_train:\n",
        "            self.unet_checkpoint = \"prev_checkpoints/cloth_segm_unet_surgery.pth\"\n",
        "\n",
        "        self.save_freq = 1000\n",
        "        self.print_freq = 10\n",
        "        self.image_log_freq = 100\n",
        "\n",
        "        self.iter = 100000\n",
        "        self.lr = 0.0002\n",
        "        self.clip_grad = 5\n",
        "\n",
        "        self.logs_dir = osp.join(\"logs\", self.name)\n",
        "        self.save_dir = osp.join(\"results\", self.name)"
      ],
      "metadata": {
        "id": "yKVTDZsxJDEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseDataLoader:\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def initialize(self, opt):\n",
        "        self.opt = opt\n",
        "        pass\n",
        "\n",
        "    def load_data():\n",
        "        return None"
      ],
      "metadata": {
        "id": "c_sB34SPRZeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import torch\n",
        "import torch.utils.data as data\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "class BaseDataset(data.Dataset):\n",
        "    def __init__(self):\n",
        "        super(BaseDataset, self).__init__()\n",
        "\n",
        "    def name(self):\n",
        "        return \"BaseDataset\"\n",
        "\n",
        "    def initialize(self, opt):\n",
        "        pass\n",
        "\n",
        "\n",
        "class Rescale_fixed(object):\n",
        "    \"\"\"Rescale the input image into given size.\n",
        "\n",
        "    Args:\n",
        "        (w,h) (tuple): output size or x (int) then resized will be done in (x,x).\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def __call__(self, image):\n",
        "        return image.resize(self.output_size, Image.BICUBIC)\n",
        "\n",
        "\n",
        "class Rescale_custom(object):\n",
        "    \"\"\"Rescale the input image and target image into randomly selected size with lower bound of min_size arg.\n",
        "\n",
        "    Args:\n",
        "        min_size (int): Minimum desired output size.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, min_size, max_size):\n",
        "        assert isinstance(min_size, (int, float))\n",
        "        self.min_size = min_size\n",
        "        self.max_size = max_size\n",
        "\n",
        "    def __call__(self, sample):\n",
        "\n",
        "        input_image, target_image = sample[\"input_image\"], sample[\"target_image\"]\n",
        "\n",
        "        assert input_image.size == target_image.size\n",
        "        w, h = input_image.size\n",
        "\n",
        "        # Randomly select size to resize\n",
        "        if min(self.max_size, h, w) > self.min_size:\n",
        "            self.output_size = np.random.randint(\n",
        "                self.min_size, min(self.max_size, h, w)\n",
        "            )\n",
        "        else:\n",
        "            self.output_size = self.min_size\n",
        "\n",
        "        # calculate new size by keeping aspect ratio same\n",
        "        if h > w:\n",
        "            new_h, new_w = self.output_size * h / w, self.output_size\n",
        "        else:\n",
        "            new_h, new_w = self.output_size, self.output_size * w / h\n",
        "\n",
        "        new_w, new_h = int(new_w), int(new_h)\n",
        "        input_image = input_image.resize((new_w, new_h), Image.BICUBIC)\n",
        "        target_image = target_image.resize((new_w, new_h), Image.BICUBIC)\n",
        "        return {\"input_image\": input_image, \"target_image\": target_image}\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.totensor = transforms.ToTensor()\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        input_image, target_image = sample[\"input_image\"], sample[\"target_image\"]\n",
        "\n",
        "        return {\n",
        "            \"input_image\": self.totensor(input_image),\n",
        "            \"target_image\": self.totensor(target_image),\n",
        "        }\n",
        "\n",
        "\n",
        "class RandomCrop_custom(object):\n",
        "    \"\"\"Crop randomly the image in a sample.\n",
        "\n",
        "    Args:\n",
        "        output_size (tuple or int): Desired output size. If int, square crop\n",
        "            is made.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size):\n",
        "        assert isinstance(output_size, (int, tuple))\n",
        "        if isinstance(output_size, int):\n",
        "            self.output_size = (output_size, output_size)\n",
        "        else:\n",
        "            assert len(output_size) == 2\n",
        "            self.output_size = output_size\n",
        "\n",
        "        self.randomcrop = transforms.RandomCrop(self.output_size)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        input_image, target_image = sample[\"input_image\"], sample[\"target_image\"]\n",
        "        cropped_imgs = self.randomcrop(torch.cat((input_image, target_image)))\n",
        "\n",
        "        return {\n",
        "            \"input_image\": cropped_imgs[\n",
        "                :3,\n",
        "                :,\n",
        "            ],\n",
        "            \"target_image\": cropped_imgs[\n",
        "                3:,\n",
        "                :,\n",
        "            ],\n",
        "        }\n",
        "\n",
        "\n",
        "class Normalize_custom(object):\n",
        "    \"\"\"Normalize given dict into given mean and standard dev\n",
        "\n",
        "    Args:\n",
        "        mean (tuple or int): Desired mean to substract from dict's tensors\n",
        "        std (tuple or int): Desired std to divide from dict's tensors\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        assert isinstance(mean, (float, tuple))\n",
        "        if isinstance(mean, float):\n",
        "            self.mean = (mean, mean, mean)\n",
        "        else:\n",
        "            assert len(mean) == 3\n",
        "            self.mean = mean\n",
        "\n",
        "        if isinstance(std, float):\n",
        "            self.std = (std, std, std)\n",
        "        else:\n",
        "            assert len(std) == 3\n",
        "            self.std = std\n",
        "\n",
        "        self.normalize = transforms.Normalize(self.mean, self.std)\n",
        "\n",
        "    def __call__(self, sample):\n",
        "        input_image, target_image = sample[\"input_image\"], sample[\"target_image\"]\n",
        "\n",
        "        return {\n",
        "            \"input_image\": self.normalize(input_image),\n",
        "            \"target_image\": self.normalize(target_image),\n",
        "        }\n",
        "\n",
        "\n",
        "class Normalize_image(object):\n",
        "    \"\"\"Normalize given tensor into given mean and standard dev\n",
        "\n",
        "    Args:\n",
        "        mean (float): Desired mean to substract from tensors\n",
        "        std (float): Desired std to divide from tensors\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, mean, std):\n",
        "        assert isinstance(mean, (float))\n",
        "        if isinstance(mean, float):\n",
        "            self.mean = mean\n",
        "\n",
        "        if isinstance(std, float):\n",
        "            self.std = std\n",
        "\n",
        "        self.normalize_1 = transforms.Normalize(self.mean, self.std)\n",
        "        self.normalize_3 = transforms.Normalize([self.mean] * 3, [self.std] * 3)\n",
        "        self.normalize_18 = transforms.Normalize([self.mean] * 18, [self.std] * 18)\n",
        "\n",
        "    def __call__(self, image_tensor):\n",
        "        if image_tensor.shape[0] == 1:\n",
        "            return self.normalize_1(image_tensor)\n",
        "\n",
        "        elif image_tensor.shape[0] == 3:\n",
        "            return self.normalize_3(image_tensor)\n",
        "\n",
        "        elif image_tensor.shape[0] == 18:\n",
        "            return self.normalize_18(image_tensor)\n",
        "\n",
        "        else:\n",
        "            assert \"Please set proper channels! Normlization implemented only for 1, 3 and 18\"\n",
        "\n",
        "###############################################################################\n",
        "# Code from\n",
        "# https://github.com/pytorch/vision/blob/master/torchvision/datasets/folder.py\n",
        "# Modified the original code so that it also loads images from the current\n",
        "# directory as well as the subdirectories\n",
        "###############################################################################\n",
        "import torch.utils.data as data\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "IMG_EXTENSIONS = [\n",
        "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
        "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP', '.tiff'\n",
        "]\n",
        "\n",
        "\n",
        "def is_image_file(filename):\n",
        "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
        "\n",
        "\n",
        "def make_dataset(dir):\n",
        "    images = []\n",
        "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
        "\n",
        "    f = dir.split('/')[-1].split('_')[-1]\n",
        "    print(dir, f)\n",
        "    dirs = os.listdir(dir)\n",
        "    for img in dirs:\n",
        "        path = os.path.join(dir, img)\n",
        "        images.append(path)\n",
        "    return images\n",
        "\n",
        "\n",
        "def make_dataset_test(dir):\n",
        "    images = []\n",
        "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
        "\n",
        "    f = dir.split('/')[-1].split('_')[-1]\n",
        "    for i in range(len([name for name in os.listdir(dir) if os.path.isfile(os.path.join(dir, name))])):\n",
        "        if f == 'label' or f == 'labelref':\n",
        "            img = str(i) + '.png'\n",
        "        else:\n",
        "            img = str(i) + '.jpg'\n",
        "        path = os.path.join(dir, img)\n",
        "        # print(path)\n",
        "        images.append(path)\n",
        "    return images\n",
        "\n",
        "\n",
        "def default_loader(path):\n",
        "    return Image.open(path).convert('RGB')\n",
        "\n",
        "\n",
        "class ImageFolder(data.Dataset):\n",
        "\n",
        "    def __init__(self, root, transform=None, return_paths=False,\n",
        "                 loader=default_loader):\n",
        "        imgs = make_dataset(root)\n",
        "        if len(imgs) == 0:\n",
        "            raise(RuntimeError(\"Found 0 images in: \" + root + \"\\n\"\n",
        "                               \"Supported image extensions are: \" +\n",
        "                               \",\".join(IMG_EXTENSIONS)))\n",
        "\n",
        "        self.root = root\n",
        "        self.imgs = imgs\n",
        "        self.transform = transform\n",
        "        self.return_paths = return_paths\n",
        "        self.loader = loader\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        path = self.imgs[index]\n",
        "        img = self.loader(path)\n",
        "        if self.transform is not None:\n",
        "            img = self.transform(img)\n",
        "        if self.return_paths:\n",
        "            return img, path\n",
        "        else:\n",
        "            return img\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)"
      ],
      "metadata": {
        "id": "_pRQSQWpRqsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import itertools\n",
        "import collections\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "class AlignedDataset(BaseDataset):\n",
        "    def initialize(self, opt):\n",
        "        self.opt = opt\n",
        "        self.image_dir = opt.image_folder\n",
        "        self.df_path = opt.df_path\n",
        "        self.width = opt.fine_width\n",
        "        self.height = opt.fine_height\n",
        "\n",
        "        # for rgb imgs\n",
        "\n",
        "        transforms_list = []\n",
        "        transforms_list += [transforms.ToTensor()]\n",
        "        transforms_list += [Normalize_image(opt.mean, opt.std)]\n",
        "        self.transform_rgb = transforms.Compose(transforms_list)\n",
        "\n",
        "        self.df = pd.read_csv(self.df_path)\n",
        "        self.image_info = collections.defaultdict(dict)\n",
        "        self.df[\"CategoryId\"] = self.df.ClassId.apply(lambda x: str(x).split(\"_\")[0])\n",
        "        temp_df = (\n",
        "            self.df.groupby(\"ImageId\")[\"EncodedPixels\", \"CategoryId\"]\n",
        "            .agg(lambda x: list(x))\n",
        "            .reset_index()\n",
        "        )\n",
        "        size_df = self.df.groupby(\"ImageId\")[\"Height\", \"Width\"].mean().reset_index()\n",
        "        temp_df = temp_df.merge(size_df, on=\"ImageId\", how=\"left\")\n",
        "        for index, row in tqdm(temp_df.iterrows(), total=len(temp_df)):\n",
        "            image_id = row[\"ImageId\"]\n",
        "            image_path = os.path.join(self.image_dir, image_id)\n",
        "            self.image_info[index][\"image_id\"] = image_id\n",
        "            self.image_info[index][\"image_path\"] = image_path\n",
        "            self.image_info[index][\"width\"] = self.width\n",
        "            self.image_info[index][\"height\"] = self.height\n",
        "            self.image_info[index][\"labels\"] = row[\"CategoryId\"]\n",
        "            self.image_info[index][\"orig_height\"] = row[\"Height\"]\n",
        "            self.image_info[index][\"orig_width\"] = row[\"Width\"]\n",
        "            self.image_info[index][\"annotations\"] = row[\"EncodedPixels\"]\n",
        "\n",
        "        self.dataset_size = len(self.image_info)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # load images ad masks\n",
        "        idx = index\n",
        "        img_path = self.image_info[idx][\"image_path\"]\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img = img.resize((self.width, self.height), resample=Image.BICUBIC)\n",
        "        image_tensor = self.transform_rgb(img)\n",
        "\n",
        "        info = self.image_info[idx]\n",
        "        mask = np.zeros(\n",
        "            (len(info[\"annotations\"]), self.width, self.height), dtype=np.uint8\n",
        "        )\n",
        "        labels = []\n",
        "        for m, (annotation, label) in enumerate(\n",
        "            zip(info[\"annotations\"], info[\"labels\"])\n",
        "        ):\n",
        "            sub_mask = self.rle_decode(\n",
        "                annotation, (info[\"orig_height\"], info[\"orig_width\"])\n",
        "            )\n",
        "            sub_mask = Image.fromarray(sub_mask)\n",
        "            sub_mask = sub_mask.resize(\n",
        "                (self.width, self.height), resample=Image.BICUBIC\n",
        "            )\n",
        "            mask[m, :, :] = sub_mask\n",
        "            labels.append(int(label) + 1)\n",
        "\n",
        "        num_objs = len(labels)\n",
        "        boxes = []\n",
        "        new_labels = []\n",
        "        new_masks = []\n",
        "\n",
        "        for i in range(num_objs):\n",
        "            try:\n",
        "                pos = np.where(mask[i, :, :])\n",
        "                xmin = np.min(pos[1])\n",
        "                xmax = np.max(pos[1])\n",
        "                ymin = np.min(pos[0])\n",
        "                ymax = np.max(pos[0])\n",
        "                if abs(xmax - xmin) >= 20 and abs(ymax - ymin) >= 20:\n",
        "                    boxes.append([xmin, ymin, xmax, ymax])\n",
        "                    new_labels.append(labels[i])\n",
        "                    new_masks.append(mask[i, :, :])\n",
        "            except ValueError:\n",
        "                continue\n",
        "\n",
        "        if len(new_labels) == 0:\n",
        "            boxes.append([0, 0, 20, 20])\n",
        "            new_labels.append(0)\n",
        "            new_masks.append(mask[0, :, :])\n",
        "\n",
        "        nmx = np.zeros((len(new_masks), self.width, self.height), dtype=np.uint8)\n",
        "        for i, n in enumerate(new_masks):\n",
        "            nmx[i, :, :] = n\n",
        "\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        labels = torch.as_tensor(new_labels, dtype=torch.int64)\n",
        "        masks = torch.as_tensor(nmx, dtype=torch.uint8)\n",
        "\n",
        "        final_label = np.zeros((self.width, self.height), dtype=np.uint8)\n",
        "        first_channel = np.zeros((self.width, self.height), dtype=np.uint8)\n",
        "        second_channel = np.zeros((self.width, self.height), dtype=np.uint8)\n",
        "        third_channel = np.zeros((self.width, self.height), dtype=np.uint8)\n",
        "\n",
        "        upperbody = [0, 1, 2, 3, 4, 5]\n",
        "        lowerbody = [6, 7, 8]\n",
        "        wholebody = [9, 10, 11, 12]\n",
        "\n",
        "        for i in range(len(labels)):\n",
        "            if labels[i] in upperbody:\n",
        "                first_channel += new_masks[i]\n",
        "            elif labels[i] in lowerbody:\n",
        "                second_channel += new_masks[i]\n",
        "            elif labels[i] in wholebody:\n",
        "                third_channel += new_masks[i]\n",
        "\n",
        "        first_channel = (first_channel > 0).astype(\"uint8\")\n",
        "        second_channel = (second_channel > 0).astype(\"uint8\")\n",
        "        third_channel = (third_channel > 0).astype(\"uint8\")\n",
        "\n",
        "        final_label = first_channel + second_channel * 2 + third_channel * 3\n",
        "        conflict_mask = (final_label <= 3).astype(\"uint8\")\n",
        "        final_label = (conflict_mask) * final_label + (1 - conflict_mask) * 1\n",
        "        target_tensor = torch.as_tensor(final_label, dtype=torch.int64)\n",
        "\n",
        "        return image_tensor, target_tensor\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_info)\n",
        "\n",
        "    def name(self):\n",
        "        return \"AlignedDataset\"\n",
        "\n",
        "    def rle_decode(self, mask_rle, shape):\n",
        "        \"\"\"\n",
        "        mask_rle: run-length as string formated: [start0] [length0] [start1] [length1]... in 1d array\n",
        "        shape: (height,width) of array to return\n",
        "        Returns numpy array according to the shape, 1 - mask, 0 - background\n",
        "        \"\"\"\n",
        "        shape = (shape[1], shape[0])\n",
        "        s = mask_rle.split()\n",
        "        # gets starts & lengths 1d arrays\n",
        "        starts, lengths = [np.asarray(x, dtype=int) for x in (s[0::2], s[1::2])]\n",
        "        starts -= 1\n",
        "        # gets ends 1d array\n",
        "        ends = starts + lengths\n",
        "        # creates blank mask image 1d array\n",
        "        shape = tuple(int(dim) for dim in shape)\n",
        "        img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
        "        # sets mark pixles\n",
        "        for lo, hi in zip(starts, ends):\n",
        "            img[lo:hi] = 1\n",
        "        # reshape as a 2d mask image\n",
        "        return img.reshape(shape).T  # Needed to align to RLE direction"
      ],
      "metadata": {
        "id": "cNGxV89yRlct"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.utils.data\n",
        "\n",
        "\n",
        "def CreateDataset(opt):\n",
        "    dataset = None\n",
        "    dataset = AlignedDataset()\n",
        "\n",
        "    print(\"dataset [%s] was created\" % (dataset.name()))\n",
        "    dataset.initialize(opt)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "class CustomDatasetDataLoader(BaseDataLoader):\n",
        "    def name(self):\n",
        "        return 'CustomDatasetDataLoader'\n",
        "\n",
        "    def initialize(self, opt):\n",
        "        BaseDataLoader.initialize(self, opt)\n",
        "        self.dataset = CreateDataset(opt)\n",
        "        self.dataloader = torch.utils.data.DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=opt.batchSize,\n",
        "            sampler=data_sampler(self.dataset,\n",
        "                                 not opt.serial_batches, opt.distributed),\n",
        "            num_workers=int(opt.nThreads),\n",
        "            pin_memory=True)\n",
        "\n",
        "    def get_loader(self):\n",
        "        return self.dataloader\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dataset), self.opt.max_dataset_size)\n",
        "\n",
        "\n",
        "def data_sampler(dataset, shuffle, distributed):\n",
        "    if distributed:\n",
        "        return torch.utils.data.distributed.DistributedSampler(dataset, shuffle=shuffle)\n",
        "\n",
        "    if shuffle:\n",
        "        return torch.utils.data.RandomSampler(dataset)\n",
        "\n",
        "    else:\n",
        "        return torch.utils.data.SequentialSampler(dataset)\n",
        "\n",
        "\n",
        "def sample_data(loader):\n",
        "    while True:\n",
        "        for batch in loader:\n",
        "            yield batch\n",
        "\n",
        "\n",
        "class CustomTestDataLoader(BaseDataLoader):\n",
        "    def name(self):\n",
        "        return 'CustomDatasetDataLoader'\n",
        "\n",
        "    def initialize(self, opt):\n",
        "        BaseDataLoader.initialize(self, opt)\n",
        "        self.dataset = CreateDataset(opt)\n",
        "        self.dataloader = torch.utils.data.DataLoader(\n",
        "            self.dataset,\n",
        "            batch_size=opt.batchSize,\n",
        "            num_workers=int(opt.nThreads),\n",
        "            pin_memory=True)\n",
        "\n",
        "    def get_loader(self):\n",
        "        return self.dataloader\n",
        "\n",
        "    def __len__(self):\n",
        "        return min(len(self.dataset), self.opt.max_dataset_size)"
      ],
      "metadata": {
        "id": "E-ky5zTyRUik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cd /content/dataset/"
      ],
      "metadata": {
        "id": "YITAsFN1TJR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import time\n",
        "import yaml\n",
        "import cv2\n",
        "import pprint\n",
        "import traceback\n",
        "import numpy as np\n",
        "\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.distributed as dist\n",
        "import torch.multiprocessing as mp\n",
        "from torch.cuda.amp import autocast\n",
        "from torch.nn.parallel import DistributedDataParallel as DDP\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchvision import models\n",
        "\n",
        "\n",
        "\n",
        "def options_printing_saving(opt):\n",
        "    os.makedirs(opt.logs_dir, exist_ok=True)\n",
        "    os.makedirs(opt.save_dir, exist_ok=True)\n",
        "    os.makedirs(os.path.join(opt.save_dir, \"images\"), exist_ok=True)\n",
        "    os.makedirs(os.path.join(opt.save_dir, \"checkpoints\"), exist_ok=True)\n",
        "\n",
        "    # Saving options in yml file\n",
        "    option_dict = vars(opt)\n",
        "    with open(os.path.join(opt.save_dir, \"training_options.yml\"), \"w\") as outfile:\n",
        "        yaml.dump(option_dict, outfile)\n",
        "\n",
        "    for key, value in option_dict.items():\n",
        "        print(key, value)\n",
        "\n",
        "\n",
        "def training_loop(opt):\n",
        "\n",
        "    if opt.distributed:\n",
        "        local_rank = int(os.environ.get(\"LOCAL_RANK\"))\n",
        "        # Unique only on individual node.\n",
        "        device = torch.device(f\"cuda:{local_rank}\")\n",
        "    else:\n",
        "        device = torch.device(\"cuda:0\")\n",
        "        local_rank = 0\n",
        "\n",
        "    u_net = U2NET(in_ch=3, out_ch=4)\n",
        "    if opt.continue_train:\n",
        "        u_net = load_checkpoint(u_net, opt.unet_checkpoint)\n",
        "    u_net = u_net.to(device)\n",
        "    u_net.train()\n",
        "\n",
        "    if local_rank == 0:\n",
        "        with open(os.path.join(opt.save_dir, \"networks.txt\"), \"w\") as outfile:\n",
        "            print(\"<----U-2-Net---->\", file=outfile)\n",
        "            print(u_net, file=outfile)\n",
        "\n",
        "    if opt.distributed:\n",
        "        u_net = nn.parallel.DistributedDataParallel(\n",
        "            u_net,\n",
        "            device_ids=[local_rank],\n",
        "            output_device=local_rank,\n",
        "            broadcast_buffers=False,\n",
        "        )\n",
        "        print(\"Going super fast with DistributedDataParallel\")\n",
        "\n",
        "    # initialize optimizer\n",
        "    optimizer = optim.Adam(\n",
        "        u_net.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0\n",
        "    )\n",
        "\n",
        "    custom_dataloader = CustomDatasetDataLoader()\n",
        "    custom_dataloader.initialize(opt)\n",
        "    loader = custom_dataloader.get_loader()\n",
        "\n",
        "    if local_rank == 0:\n",
        "        dataset_size = len(custom_dataloader)\n",
        "        print(\"Total number of images avaliable for training: %d\" % dataset_size)\n",
        "        writer = SummaryWriter(opt.logs_dir)\n",
        "        print(\"Entering training loop!\")\n",
        "\n",
        "    # loss function\n",
        "    weights = np.array([1, 1.5, 1.5, 1.5], dtype=np.float32)\n",
        "    weights = torch.from_numpy(weights).to(device)\n",
        "    loss_CE = nn.CrossEntropyLoss(weight=weights).to(device)\n",
        "\n",
        "    pbar = range(opt.iter)\n",
        "    get_data = sample_data(loader)\n",
        "\n",
        "    start_time = time.time()\n",
        "    # Main training loop\n",
        "    for itr in pbar:\n",
        "        data_batch = next(get_data)\n",
        "        image, label = data_batch\n",
        "        image = Variable(image.to(device))\n",
        "        label = label.type(torch.long)\n",
        "        label = Variable(label.to(device))\n",
        "\n",
        "        d0, d1, d2, d3, d4, d5, d6 = u_net(image)\n",
        "\n",
        "        loss0 = loss_CE(d0, label)\n",
        "        loss1 = loss_CE(d1, label)\n",
        "        loss2 = loss_CE(d2, label)\n",
        "        loss3 = loss_CE(d3, label)\n",
        "        loss4 = loss_CE(d4, label)\n",
        "        loss5 = loss_CE(d5, label)\n",
        "        loss6 = loss_CE(d6, label)\n",
        "        del d1, d2, d3, d4, d5, d6\n",
        "\n",
        "        total_loss = loss0 * 1.5 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
        "\n",
        "        for param in u_net.parameters():\n",
        "            param.grad = None\n",
        "\n",
        "        total_loss.backward()\n",
        "        if opt.clip_grad != 0:\n",
        "            nn.utils.clip_grad_norm_(u_net.parameters(), opt.clip_grad)\n",
        "        optimizer.step()\n",
        "\n",
        "        if local_rank == 0:\n",
        "            # printing and saving work\n",
        "            if itr % opt.print_freq == 0:\n",
        "                pprint.pprint(\n",
        "                    \"[step-{:08d}] [time-{:.3f}] [total_loss-{:.6f}]  [loss0-{:.6f}]\".format(\n",
        "                        itr, time.time() - start_time, total_loss, loss0\n",
        "                    )\n",
        "                )\n",
        "\n",
        "            if itr % opt.image_log_freq == 0:\n",
        "                d0 = F.log_softmax(d0, dim=1)\n",
        "                d0 = torch.max(d0, dim=1, keepdim=True)[1]\n",
        "                visuals = [[image, torch.unsqueeze(label, dim=1) * 85, d0 * 85]]\n",
        "                board_add_images(writer, \"grid\", visuals, itr)\n",
        "\n",
        "            writer.add_scalar(\"total_loss\", total_loss, itr)\n",
        "            writer.add_scalar(\"loss0\", loss0, itr)\n",
        "\n",
        "            if itr % opt.save_freq == 0:\n",
        "                save_checkpoints(opt, itr, u_net)\n",
        "\n",
        "    print(\"Training done!\")\n",
        "    if local_rank == 0:\n",
        "        itr += 1\n",
        "        save_checkpoints(opt, itr, u_net)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    opt = parser()\n",
        "\n",
        "    if opt.distributed:\n",
        "        if int(os.environ.get(\"LOCAL_RANK\")) == 0:\n",
        "            options_printing_saving(opt)\n",
        "    else:\n",
        "        options_printing_saving(opt)\n",
        "\n",
        "    try:\n",
        "        if opt.distributed:\n",
        "            print(\"Initialize Process Group...\")\n",
        "            torch.distributed.init_process_group(backend=\"nccl\", init_method=\"env://\")\n",
        "            synchronize()\n",
        "\n",
        "        set_seed(1000)\n",
        "        training_loop(opt)\n",
        "        cleanup(opt.distributed)\n",
        "        print(\"Exiting..............\")\n",
        "\n",
        "    except KeyboardInterrupt:\n",
        "        cleanup(opt.distributed)\n",
        "\n",
        "    except Exception:\n",
        "        traceback.print_exc(file=sys.stdout)\n",
        "        cleanup(opt.distributed)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BtSAbIDAsF8",
        "outputId": "ff5273ad-d4a5-4428-c8d2-84df35376191"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "name training_cloth_segm_u2net_exp1\n",
            "image_folder /content/dataset/train/\n",
            "df_path /content/dataset/train.csv\n",
            "distributed False\n",
            "isTrain True\n",
            "fine_width 768\n",
            "fine_height 768\n",
            "mean 0.5\n",
            "std 0.5\n",
            "batchSize 2\n",
            "nThreads 2\n",
            "max_dataset_size inf\n",
            "serial_batches False\n",
            "continue_train True\n",
            "unet_checkpoint prev_checkpoints/cloth_segm_unet_surgery.pth\n",
            "save_freq 1000\n",
            "print_freq 10\n",
            "image_log_freq 100\n",
            "iter 100000\n",
            "lr 0.0002\n",
            "clip_grad 5\n",
            "logs_dir logs/training_cloth_segm_u2net_exp1\n",
            "save_dir results/training_cloth_segm_u2net_exp1\n",
            "----checkpoints loaded from path: prev_checkpoints/cloth_segm_unet_surgery.pth----\n",
            "dataset [AlignedDataset] was created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 45195/45195 [00:04<00:00, 10809.42it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of images avaliable for training: 45195\n",
            "Entering training loop!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:3769: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
            "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'[step-00000000] [time-70.798] [total_loss-10.427507]  [loss0-1.401052]'\n",
            "results/training_cloth_segm_u2net_exp1/checkpoints/itr_00000000_u2net.pth\n",
            "'[step-00000010] [time-95.518] [total_loss-10.259898]  [loss0-1.646647]'\n",
            "'[step-00000020] [time-122.206] [total_loss-4.788110]  [loss0-0.660185]'\n",
            "'[step-00000030] [time-144.509] [total_loss-5.270166]  [loss0-0.667101]'\n",
            "'[step-00000040] [time-172.507] [total_loss-3.836240]  [loss0-0.484880]'\n",
            "'[step-00000050] [time-197.749] [total_loss-3.102251]  [loss0-0.481346]'\n",
            "'[step-00000060] [time-227.452] [total_loss-2.119591]  [loss0-0.292702]'\n",
            "'[step-00000070] [time-245.729] [total_loss-9.094823]  [loss0-1.066927]'\n",
            "'[step-00000080] [time-260.585] [total_loss-4.226876]  [loss0-0.604385]'\n",
            "'[step-00000090] [time-282.482] [total_loss-2.408255]  [loss0-0.330811]'\n",
            "'[step-00000100] [time-302.038] [total_loss-1.885244]  [loss0-0.267589]'\n",
            "'[step-00000110] [time-320.561] [total_loss-1.577716]  [loss0-0.231840]'\n",
            "'[step-00000120] [time-341.656] [total_loss-3.819477]  [loss0-0.491688]'\n",
            "'[step-00000130] [time-356.680] [total_loss-1.686012]  [loss0-0.225486]'\n",
            "'[step-00000140] [time-372.332] [total_loss-4.556283]  [loss0-0.624774]'\n",
            "'[step-00000150] [time-392.936] [total_loss-3.772911]  [loss0-0.481699]'\n",
            "'[step-00000160] [time-409.861] [total_loss-3.186395]  [loss0-0.414089]'\n",
            "'[step-00000170] [time-439.057] [total_loss-1.809359]  [loss0-0.237056]'\n",
            "'[step-00000180] [time-453.421] [total_loss-1.962488]  [loss0-0.252722]'\n",
            "'[step-00000190] [time-475.056] [total_loss-6.047333]  [loss0-0.796285]'\n",
            "'[step-00000200] [time-497.446] [total_loss-20.284945]  [loss0-2.587927]'\n",
            "'[step-00000210] [time-524.168] [total_loss-3.782357]  [loss0-0.486938]'\n",
            "'[step-00000220] [time-548.422] [total_loss-2.275199]  [loss0-0.296047]'\n",
            "'[step-00000230] [time-566.688] [total_loss-4.446818]  [loss0-0.617117]'\n",
            "'[step-00000240] [time-589.320] [total_loss-2.961836]  [loss0-0.356950]'\n",
            "'[step-00000250] [time-611.872] [total_loss-1.823226]  [loss0-0.262224]'\n",
            "'[step-00000260] [time-628.726] [total_loss-5.483504]  [loss0-0.694378]'\n",
            "'[step-00000270] [time-645.905] [total_loss-3.220820]  [loss0-0.409668]'\n",
            "'[step-00000280] [time-668.139] [total_loss-1.437447]  [loss0-0.175234]'\n",
            "'[step-00000290] [time-696.038] [total_loss-1.952597]  [loss0-0.245701]'\n",
            "'[step-00000300] [time-715.891] [total_loss-1.803436]  [loss0-0.215554]'\n",
            "'[step-00000310] [time-732.108] [total_loss-1.893785]  [loss0-0.248945]'\n",
            "'[step-00000320] [time-757.200] [total_loss-1.286018]  [loss0-0.179547]'\n",
            "'[step-00000330] [time-786.732] [total_loss-1.010005]  [loss0-0.115030]'\n",
            "'[step-00000340] [time-804.855] [total_loss-2.312067]  [loss0-0.277228]'\n",
            "'[step-00000350] [time-825.520] [total_loss-2.130965]  [loss0-0.282631]'\n",
            "'[step-00000360] [time-847.940] [total_loss-3.098411]  [loss0-0.396629]'\n",
            "'[step-00000370] [time-864.504] [total_loss-3.120736]  [loss0-0.412880]'\n",
            "'[step-00000380] [time-884.020] [total_loss-2.871028]  [loss0-0.377117]'\n",
            "'[step-00000390] [time-899.599] [total_loss-4.996789]  [loss0-0.637789]'\n",
            "'[step-00000400] [time-914.665] [total_loss-2.730317]  [loss0-0.320510]'\n",
            "'[step-00000410] [time-931.748] [total_loss-1.390475]  [loss0-0.173582]'\n",
            "'[step-00000420] [time-947.055] [total_loss-2.170958]  [loss0-0.241333]'\n",
            "'[step-00000430] [time-967.227] [total_loss-2.408316]  [loss0-0.282874]'\n",
            "'[step-00000440] [time-996.074] [total_loss-2.724913]  [loss0-0.353016]'\n",
            "'[step-00000450] [time-1018.650] [total_loss-2.629102]  [loss0-0.332990]'\n",
            "'[step-00000460] [time-1042.087] [total_loss-2.772343]  [loss0-0.375808]'\n",
            "'[step-00000470] [time-1064.960] [total_loss-2.252213]  [loss0-0.280147]'\n",
            "'[step-00000480] [time-1081.847] [total_loss-3.174958]  [loss0-0.410066]'\n",
            "'[step-00000490] [time-1102.880] [total_loss-1.800860]  [loss0-0.218295]'\n",
            "'[step-00000500] [time-1125.230] [total_loss-5.632808]  [loss0-0.701456]'\n",
            "'[step-00000510] [time-1141.959] [total_loss-6.447134]  [loss0-0.766989]'\n",
            "'[step-00000520] [time-1163.047] [total_loss-1.203685]  [loss0-0.150944]'\n",
            "'[step-00000530] [time-1182.740] [total_loss-2.591335]  [loss0-0.316944]'\n",
            "'[step-00000540] [time-1211.010] [total_loss-2.528862]  [loss0-0.339866]'\n",
            "'[step-00000550] [time-1232.217] [total_loss-3.709642]  [loss0-0.437082]'\n",
            "'[step-00000560] [time-1258.506] [total_loss-1.963056]  [loss0-0.199880]'\n",
            "'[step-00000570] [time-1278.264] [total_loss-0.938508]  [loss0-0.113001]'\n",
            "'[step-00000580] [time-1298.284] [total_loss-2.175020]  [loss0-0.257787]'\n",
            "'[step-00000590] [time-1313.406] [total_loss-2.736937]  [loss0-0.359598]'\n",
            "'[step-00000600] [time-1329.870] [total_loss-2.684892]  [loss0-0.333413]'\n",
            "'[step-00000610] [time-1348.307] [total_loss-3.689072]  [loss0-0.469506]'\n",
            "'[step-00000620] [time-1368.362] [total_loss-3.330083]  [loss0-0.434891]'\n",
            "'[step-00000630] [time-1392.526] [total_loss-2.349901]  [loss0-0.317402]'\n",
            "'[step-00000640] [time-1410.597] [total_loss-2.074899]  [loss0-0.264481]'\n",
            "'[step-00000650] [time-1428.419] [total_loss-3.020433]  [loss0-0.378180]'\n",
            "'[step-00000660] [time-1445.147] [total_loss-0.951761]  [loss0-0.139156]'\n",
            "'[step-00000670] [time-1465.911] [total_loss-2.116728]  [loss0-0.218674]'\n",
            "'[step-00000680] [time-1481.575] [total_loss-2.218241]  [loss0-0.245980]'\n",
            "'[step-00000690] [time-1497.106] [total_loss-2.219718]  [loss0-0.261523]'\n",
            "'[step-00000700] [time-1512.226] [total_loss-2.922519]  [loss0-0.392900]'\n",
            "'[step-00000710] [time-1527.938] [total_loss-1.160622]  [loss0-0.142457]'\n",
            "'[step-00000720] [time-1549.364] [total_loss-1.529106]  [loss0-0.205616]'\n",
            "'[step-00000730] [time-1564.492] [total_loss-2.159521]  [loss0-0.265107]'\n",
            "'[step-00000740] [time-1583.350] [total_loss-3.424551]  [loss0-0.464004]'\n",
            "'[step-00000750] [time-1601.332] [total_loss-2.122751]  [loss0-0.251437]'\n",
            "'[step-00000760] [time-1616.229] [total_loss-0.829949]  [loss0-0.093679]'\n",
            "'[step-00000770] [time-1634.799] [total_loss-1.569415]  [loss0-0.172989]'\n",
            "'[step-00000780] [time-1656.711] [total_loss-2.335474]  [loss0-0.277039]'\n",
            "'[step-00000790] [time-1671.841] [total_loss-2.085689]  [loss0-0.257225]'\n",
            "'[step-00000800] [time-1695.335] [total_loss-1.457123]  [loss0-0.161114]'\n",
            "'[step-00000810] [time-1713.509] [total_loss-1.831472]  [loss0-0.239226]'\n",
            "'[step-00000820] [time-1736.496] [total_loss-2.946433]  [loss0-0.369246]'\n",
            "'[step-00000830] [time-1751.883] [total_loss-2.541857]  [loss0-0.323965]'\n",
            "'[step-00000840] [time-1779.864] [total_loss-2.356249]  [loss0-0.316912]'\n",
            "'[step-00000850] [time-1801.597] [total_loss-1.801003]  [loss0-0.200937]'\n",
            "'[step-00000860] [time-1819.065] [total_loss-1.422258]  [loss0-0.163324]'\n",
            "'[step-00000870] [time-1834.980] [total_loss-3.255985]  [loss0-0.393839]'\n",
            "'[step-00000880] [time-1850.998] [total_loss-2.211994]  [loss0-0.276770]'\n",
            "'[step-00000890] [time-1867.965] [total_loss-0.446583]  [loss0-0.045042]'\n",
            "'[step-00000900] [time-1888.983] [total_loss-1.599324]  [loss0-0.184596]'\n",
            "'[step-00000910] [time-1914.033] [total_loss-0.981139]  [loss0-0.121627]'\n",
            "'[step-00000920] [time-1930.230] [total_loss-1.450216]  [loss0-0.165784]'\n",
            "'[step-00000930] [time-1951.143] [total_loss-3.637098]  [loss0-0.431272]'\n",
            "'[step-00000940] [time-1970.851] [total_loss-2.428992]  [loss0-0.297629]'\n",
            "'[step-00000950] [time-1988.128] [total_loss-3.281785]  [loss0-0.421367]'\n",
            "'[step-00000960] [time-2003.521] [total_loss-10.595817]  [loss0-1.455403]'\n",
            "'[step-00000970] [time-2028.403] [total_loss-1.857958]  [loss0-0.217242]'\n",
            "'[step-00000980] [time-2049.465] [total_loss-1.684754]  [loss0-0.228979]'\n",
            "'[step-00000990] [time-2068.925] [total_loss-1.686300]  [loss0-0.208440]'\n",
            "'[step-00001000] [time-2099.208] [total_loss-4.613607]  [loss0-0.581196]'\n",
            "results/training_cloth_segm_u2net_exp1/checkpoints/itr_00001000_u2net.pth\n",
            "'[step-00001010] [time-2120.162] [total_loss-5.475006]  [loss0-0.723865]'\n",
            "'[step-00001020] [time-2135.205] [total_loss-2.759106]  [loss0-0.337075]'\n",
            "'[step-00001030] [time-2153.063] [total_loss-0.850927]  [loss0-0.095524]'\n",
            "'[step-00001040] [time-2168.381] [total_loss-0.733063]  [loss0-0.089805]'\n",
            "'[step-00001050] [time-2186.285] [total_loss-1.419512]  [loss0-0.156544]'\n",
            "'[step-00001060] [time-2201.550] [total_loss-3.096892]  [loss0-0.405156]'\n",
            "'[step-00001070] [time-2215.930] [total_loss-2.449061]  [loss0-0.290072]'\n",
            "'[step-00001080] [time-2232.389] [total_loss-1.652482]  [loss0-0.216569]'\n",
            "'[step-00001090] [time-2249.896] [total_loss-3.015913]  [loss0-0.347964]'\n",
            "'[step-00001100] [time-2271.529] [total_loss-2.405269]  [loss0-0.358687]'\n",
            "'[step-00001110] [time-2288.114] [total_loss-1.163816]  [loss0-0.123660]'\n",
            "'[step-00001120] [time-2309.399] [total_loss-1.802381]  [loss0-0.237114]'\n",
            "'[step-00001130] [time-2324.118] [total_loss-1.289426]  [loss0-0.165917]'\n",
            "'[step-00001140] [time-2341.092] [total_loss-6.924450]  [loss0-0.821642]'\n",
            "'[step-00001150] [time-2356.475] [total_loss-1.511242]  [loss0-0.193593]'\n",
            "'[step-00001160] [time-2377.597] [total_loss-3.745905]  [loss0-0.436371]'\n",
            "'[step-00001170] [time-2400.723] [total_loss-2.494462]  [loss0-0.311614]'\n",
            "'[step-00001180] [time-2422.720] [total_loss-3.141000]  [loss0-0.407797]'\n",
            "'[step-00001190] [time-2447.104] [total_loss-2.355906]  [loss0-0.274083]'\n",
            "'[step-00001200] [time-2466.867] [total_loss-1.900935]  [loss0-0.222403]'\n",
            "'[step-00001210] [time-2489.050] [total_loss-1.943085]  [loss0-0.215031]'\n",
            "'[step-00001220] [time-2504.755] [total_loss-2.273322]  [loss0-0.288384]'\n",
            "'[step-00001230] [time-2519.188] [total_loss-5.873066]  [loss0-0.812629]'\n",
            "'[step-00001240] [time-2537.260] [total_loss-0.450417]  [loss0-0.051612]'\n",
            "'[step-00001250] [time-2558.454] [total_loss-1.765822]  [loss0-0.229716]'\n",
            "'[step-00001260] [time-2592.309] [total_loss-12.350386]  [loss0-1.637870]'\n",
            "'[step-00001270] [time-2611.142] [total_loss-1.858968]  [loss0-0.253582]'\n",
            "'[step-00001280] [time-2643.402] [total_loss-1.114799]  [loss0-0.120545]'\n",
            "'[step-00001290] [time-2667.859] [total_loss-2.227890]  [loss0-0.271160]'\n",
            "'[step-00001300] [time-2688.683] [total_loss-4.126130]  [loss0-0.523591]'\n",
            "'[step-00001310] [time-2704.191] [total_loss-1.278265]  [loss0-0.160293]'\n",
            "'[step-00001320] [time-2721.766] [total_loss-0.958694]  [loss0-0.116583]'\n",
            "'[step-00001330] [time-2744.067] [total_loss-0.895674]  [loss0-0.103273]'\n",
            "'[step-00001340] [time-2760.800] [total_loss-1.904493]  [loss0-0.214034]'\n",
            "'[step-00001350] [time-2775.215] [total_loss-1.759645]  [loss0-0.218911]'\n",
            "'[step-00001360] [time-2790.477] [total_loss-4.582065]  [loss0-0.511114]'\n",
            "'[step-00001370] [time-2807.442] [total_loss-5.619952]  [loss0-0.801341]'\n",
            "'[step-00001380] [time-2839.793] [total_loss-1.106582]  [loss0-0.128997]'\n",
            "'[step-00001390] [time-2860.005] [total_loss-4.316627]  [loss0-0.592160]'\n",
            "'[step-00001400] [time-2876.874] [total_loss-2.939438]  [loss0-0.392566]'\n",
            "'[step-00001410] [time-2892.939] [total_loss-1.893551]  [loss0-0.240768]'\n",
            "'[step-00001420] [time-2909.480] [total_loss-1.923267]  [loss0-0.259983]'\n",
            "'[step-00001430] [time-2931.476] [total_loss-1.882940]  [loss0-0.208518]'\n",
            "'[step-00001440] [time-2957.617] [total_loss-1.680131]  [loss0-0.176462]'\n",
            "'[step-00001450] [time-2972.616] [total_loss-7.001890]  [loss0-0.979619]'\n",
            "'[step-00001460] [time-2990.973] [total_loss-3.644392]  [loss0-0.529294]'\n",
            "'[step-00001470] [time-3016.957] [total_loss-5.008628]  [loss0-0.612548]'\n",
            "'[step-00001480] [time-3036.144] [total_loss-2.053023]  [loss0-0.262789]'\n",
            "'[step-00001490] [time-3056.322] [total_loss-1.109399]  [loss0-0.143850]'\n",
            "'[step-00001500] [time-3072.051] [total_loss-1.937571]  [loss0-0.237515]'\n",
            "'[step-00001510] [time-3097.432] [total_loss-5.008007]  [loss0-0.621334]'\n",
            "'[step-00001520] [time-3112.949] [total_loss-0.937742]  [loss0-0.107461]'\n",
            "'[step-00001530] [time-3129.350] [total_loss-1.448831]  [loss0-0.161064]'\n",
            "'[step-00001540] [time-3144.911] [total_loss-1.042263]  [loss0-0.123331]'\n",
            "'[step-00001550] [time-3167.959] [total_loss-1.214831]  [loss0-0.155193]'\n",
            "'[step-00001560] [time-3183.713] [total_loss-3.913215]  [loss0-0.453117]'\n",
            "'[step-00001570] [time-3209.925] [total_loss-1.427013]  [loss0-0.174171]'\n",
            "'[step-00001580] [time-3228.653] [total_loss-0.787415]  [loss0-0.091690]'\n",
            "'[step-00001590] [time-3247.775] [total_loss-1.118403]  [loss0-0.125366]'\n",
            "'[step-00001600] [time-3271.612] [total_loss-1.333650]  [loss0-0.158797]'\n",
            "'[step-00001610] [time-3296.053] [total_loss-2.462297]  [loss0-0.248668]'\n",
            "'[step-00001620] [time-3310.615] [total_loss-3.423490]  [loss0-0.404124]'\n",
            "'[step-00001630] [time-3329.675] [total_loss-5.900088]  [loss0-0.852633]'\n",
            "'[step-00001640] [time-3346.483] [total_loss-1.101519]  [loss0-0.111184]'\n",
            "'[step-00001650] [time-3368.763] [total_loss-1.197838]  [loss0-0.142712]'\n",
            "'[step-00001660] [time-3394.443] [total_loss-2.266861]  [loss0-0.319050]'\n",
            "'[step-00001670] [time-3418.495] [total_loss-1.572415]  [loss0-0.197029]'\n",
            "'[step-00001680] [time-3434.212] [total_loss-2.747123]  [loss0-0.341336]'\n",
            "'[step-00001690] [time-3448.692] [total_loss-2.989331]  [loss0-0.414466]'\n",
            "'[step-00001700] [time-3469.284] [total_loss-0.900986]  [loss0-0.105940]'\n",
            "'[step-00001710] [time-3485.345] [total_loss-1.090936]  [loss0-0.135800]'\n",
            "'[step-00001720] [time-3500.121] [total_loss-1.622365]  [loss0-0.177297]'\n",
            "'[step-00001730] [time-3524.571] [total_loss-1.570921]  [loss0-0.177399]'\n",
            "'[step-00001740] [time-3545.551] [total_loss-5.930951]  [loss0-0.745656]'\n",
            "'[step-00001750] [time-3565.498] [total_loss-1.273287]  [loss0-0.135211]'\n",
            "'[step-00001760] [time-3593.015] [total_loss-1.908110]  [loss0-0.226355]'\n",
            "'[step-00001770] [time-3609.438] [total_loss-0.834300]  [loss0-0.089700]'\n",
            "'[step-00001780] [time-3624.027] [total_loss-2.339445]  [loss0-0.290837]'\n",
            "'[step-00001790] [time-3646.003] [total_loss-2.156340]  [loss0-0.256907]'\n",
            "'[step-00001800] [time-3664.750] [total_loss-1.900169]  [loss0-0.205625]'\n",
            "'[step-00001810] [time-3682.640] [total_loss-0.685347]  [loss0-0.072990]'\n",
            "'[step-00001820] [time-3712.821] [total_loss-1.859674]  [loss0-0.191956]'\n",
            "'[step-00001830] [time-3732.739] [total_loss-5.276001]  [loss0-0.717449]'\n",
            "'[step-00001840] [time-3757.660] [total_loss-0.923328]  [loss0-0.105275]'\n",
            "'[step-00001850] [time-3779.164] [total_loss-2.216524]  [loss0-0.245714]'\n",
            "'[step-00001860] [time-3793.987] [total_loss-0.563041]  [loss0-0.053105]'\n",
            "'[step-00001870] [time-3815.530] [total_loss-6.521505]  [loss0-0.846358]'\n",
            "'[step-00001880] [time-3833.969] [total_loss-2.487477]  [loss0-0.274327]'\n",
            "'[step-00001890] [time-3849.547] [total_loss-1.022685]  [loss0-0.113322]'\n",
            "'[step-00001900] [time-3882.321] [total_loss-3.204556]  [loss0-0.360181]'\n",
            "'[step-00001910] [time-3900.416] [total_loss-2.112148]  [loss0-0.256750]'\n",
            "'[step-00001920] [time-3915.931] [total_loss-1.483086]  [loss0-0.173967]'\n",
            "'[step-00001930] [time-3940.801] [total_loss-1.469971]  [loss0-0.161866]'\n",
            "'[step-00001940] [time-3962.593] [total_loss-2.905159]  [loss0-0.345222]'\n",
            "'[step-00001950] [time-3995.396] [total_loss-0.964743]  [loss0-0.097301]'\n",
            "'[step-00001960] [time-4016.179] [total_loss-1.268649]  [loss0-0.142139]'\n",
            "'[step-00001970] [time-4031.745] [total_loss-1.011609]  [loss0-0.118351]'\n",
            "'[step-00001980] [time-4050.973] [total_loss-3.181196]  [loss0-0.408785]'\n",
            "'[step-00001990] [time-4070.174] [total_loss-0.845705]  [loss0-0.096375]'\n",
            "'[step-00002000] [time-4095.352] [total_loss-1.644029]  [loss0-0.213672]'\n",
            "results/training_cloth_segm_u2net_exp1/checkpoints/itr_00002000_u2net.pth\n",
            "'[step-00002010] [time-4113.263] [total_loss-6.049666]  [loss0-0.783388]'\n",
            "'[step-00002020] [time-4131.021] [total_loss-1.889981]  [loss0-0.268261]'\n",
            "'[step-00002030] [time-4148.414] [total_loss-2.544099]  [loss0-0.329660]'\n",
            "'[step-00002040] [time-4178.637] [total_loss-1.485713]  [loss0-0.179865]'\n",
            "'[step-00002050] [time-4195.950] [total_loss-1.045577]  [loss0-0.139022]'\n",
            "'[step-00002060] [time-4212.614] [total_loss-0.579143]  [loss0-0.063671]'\n",
            "'[step-00002070] [time-4234.190] [total_loss-1.227734]  [loss0-0.144535]'\n",
            "'[step-00002080] [time-4250.472] [total_loss-0.710160]  [loss0-0.090576]'\n",
            "'[step-00002090] [time-4266.999] [total_loss-2.959608]  [loss0-0.363536]'\n",
            "'[step-00002100] [time-4284.670] [total_loss-1.485881]  [loss0-0.159540]'\n",
            "'[step-00002110] [time-4303.667] [total_loss-1.023595]  [loss0-0.119097]'\n",
            "'[step-00002120] [time-4327.359] [total_loss-0.932636]  [loss0-0.105101]'\n",
            "'[step-00002130] [time-4361.804] [total_loss-0.611703]  [loss0-0.067504]'\n",
            "'[step-00002140] [time-4377.378] [total_loss-3.200342]  [loss0-0.419580]'\n",
            "'[step-00002150] [time-4394.108] [total_loss-1.078645]  [loss0-0.139761]'\n",
            "'[step-00002160] [time-4421.223] [total_loss-4.672269]  [loss0-0.547807]'\n",
            "'[step-00002170] [time-4440.135] [total_loss-0.844085]  [loss0-0.089017]'\n",
            "'[step-00002180] [time-4456.329] [total_loss-1.027443]  [loss0-0.121395]'\n",
            "'[step-00002190] [time-4471.037] [total_loss-2.882864]  [loss0-0.344634]'\n",
            "'[step-00002200] [time-4490.464] [total_loss-3.303984]  [loss0-0.432343]'\n",
            "'[step-00002210] [time-4505.610] [total_loss-1.163411]  [loss0-0.137490]'\n",
            "'[step-00002220] [time-4520.582] [total_loss-1.005263]  [loss0-0.113031]'\n",
            "'[step-00002230] [time-4537.210] [total_loss-1.210236]  [loss0-0.120641]'\n",
            "'[step-00002240] [time-4566.837] [total_loss-1.048700]  [loss0-0.112863]'\n",
            "'[step-00002250] [time-4596.141] [total_loss-0.815242]  [loss0-0.093876]'\n",
            "'[step-00002260] [time-4617.551] [total_loss-5.182628]  [loss0-0.670743]'\n",
            "'[step-00002270] [time-4635.555] [total_loss-0.558500]  [loss0-0.060176]'\n",
            "'[step-00002280] [time-4655.533] [total_loss-2.440467]  [loss0-0.287813]'\n",
            "'[step-00002290] [time-4674.108] [total_loss-2.102939]  [loss0-0.257339]'\n",
            "'[step-00002300] [time-4693.662] [total_loss-2.346254]  [loss0-0.285868]'\n",
            "'[step-00002310] [time-4709.320] [total_loss-1.983907]  [loss0-0.260797]'\n",
            "'[step-00002320] [time-4730.325] [total_loss-2.893638]  [loss0-0.332753]'\n",
            "'[step-00002330] [time-4755.830] [total_loss-1.393635]  [loss0-0.145788]'\n",
            "'[step-00002340] [time-4780.654] [total_loss-0.846291]  [loss0-0.098274]'\n",
            "'[step-00002350] [time-4796.580] [total_loss-1.050120]  [loss0-0.121059]'\n",
            "'[step-00002360] [time-4825.334] [total_loss-1.153614]  [loss0-0.127878]'\n",
            "'[step-00002370] [time-4843.482] [total_loss-6.857666]  [loss0-0.896382]'\n",
            "'[step-00002380] [time-4867.076] [total_loss-2.595544]  [loss0-0.296919]'\n",
            "'[step-00002390] [time-4885.223] [total_loss-1.570659]  [loss0-0.198447]'\n",
            "'[step-00002400] [time-4902.314] [total_loss-0.992501]  [loss0-0.101585]'\n",
            "'[step-00002410] [time-4925.400] [total_loss-0.652532]  [loss0-0.078876]'\n",
            "'[step-00002420] [time-4956.456] [total_loss-1.318871]  [loss0-0.159859]'\n",
            "'[step-00002430] [time-4973.328] [total_loss-0.539534]  [loss0-0.057189]'\n",
            "'[step-00002440] [time-5001.048] [total_loss-0.867845]  [loss0-0.093993]'\n",
            "'[step-00002450] [time-5030.078] [total_loss-0.635705]  [loss0-0.069977]'\n",
            "'[step-00002460] [time-5046.789] [total_loss-1.008597]  [loss0-0.092569]'\n",
            "'[step-00002470] [time-5062.491] [total_loss-2.237845]  [loss0-0.266866]'\n",
            "'[step-00002480] [time-5085.672] [total_loss-4.284409]  [loss0-0.573511]'\n",
            "'[step-00002490] [time-5112.378] [total_loss-1.401957]  [loss0-0.160913]'\n",
            "'[step-00002500] [time-5133.990] [total_loss-0.656347]  [loss0-0.071777]'\n",
            "'[step-00002510] [time-5164.802] [total_loss-1.120716]  [loss0-0.114837]'\n",
            "'[step-00002520] [time-5184.531] [total_loss-0.892620]  [loss0-0.108221]'\n",
            "'[step-00002530] [time-5210.262] [total_loss-2.582325]  [loss0-0.344067]'\n",
            "'[step-00002540] [time-5226.012] [total_loss-1.830079]  [loss0-0.213664]'\n",
            "'[step-00002550] [time-5249.004] [total_loss-0.709485]  [loss0-0.077860]'\n",
            "'[step-00002560] [time-5274.944] [total_loss-0.477587]  [loss0-0.046868]'\n",
            "'[step-00002570] [time-5293.411] [total_loss-1.981084]  [loss0-0.238503]'\n",
            "'[step-00002580] [time-5310.492] [total_loss-1.302139]  [loss0-0.154416]'\n",
            "'[step-00002590] [time-5328.545] [total_loss-0.712007]  [loss0-0.087205]'\n",
            "'[step-00002600] [time-5355.053] [total_loss-0.601115]  [loss0-0.069067]'\n",
            "'[step-00002610] [time-5372.513] [total_loss-1.779356]  [loss0-0.203969]'\n",
            "'[step-00002620] [time-5395.923] [total_loss-5.966919]  [loss0-0.744689]'\n",
            "'[step-00002630] [time-5413.907] [total_loss-0.792237]  [loss0-0.079083]'\n",
            "'[step-00002640] [time-5429.038] [total_loss-1.092661]  [loss0-0.121004]'\n",
            "'[step-00002650] [time-5446.570] [total_loss-2.425787]  [loss0-0.295856]'\n",
            "'[step-00002660] [time-5463.460] [total_loss-1.691252]  [loss0-0.228397]'\n",
            "'[step-00002670] [time-5484.306] [total_loss-0.795404]  [loss0-0.114936]'\n",
            "'[step-00002680] [time-5501.570] [total_loss-1.132367]  [loss0-0.113532]'\n",
            "'[step-00002690] [time-5522.293] [total_loss-1.630057]  [loss0-0.214244]'\n",
            "'[step-00002700] [time-5542.712] [total_loss-1.318731]  [loss0-0.145809]'\n",
            "'[step-00002710] [time-5564.861] [total_loss-0.950134]  [loss0-0.125828]'\n",
            "'[step-00002720] [time-5581.998] [total_loss-2.839277]  [loss0-0.372746]'\n",
            "'[step-00002730] [time-5597.527] [total_loss-0.552608]  [loss0-0.048226]'\n",
            "'[step-00002740] [time-5615.164] [total_loss-2.767626]  [loss0-0.330800]'\n",
            "'[step-00002750] [time-5637.882] [total_loss-1.411773]  [loss0-0.151257]'\n",
            "'[step-00002760] [time-5651.825] [total_loss-2.987428]  [loss0-0.377405]'\n",
            "'[step-00002770] [time-5667.463] [total_loss-2.159412]  [loss0-0.269191]'\n",
            "'[step-00002780] [time-5690.099] [total_loss-2.577322]  [loss0-0.299214]'\n",
            "'[step-00002790] [time-5715.347] [total_loss-1.672120]  [loss0-0.179114]'\n",
            "'[step-00002800] [time-5735.782] [total_loss-3.732070]  [loss0-0.456009]'\n",
            "'[step-00002810] [time-5759.087] [total_loss-2.424847]  [loss0-0.310247]'\n",
            "'[step-00002820] [time-5778.253] [total_loss-1.677909]  [loss0-0.194711]'\n",
            "'[step-00002830] [time-5799.535] [total_loss-3.367277]  [loss0-0.415810]'\n",
            "'[step-00002840] [time-5815.718] [total_loss-1.989242]  [loss0-0.233498]'\n",
            "'[step-00002850] [time-5833.827] [total_loss-3.515732]  [loss0-0.383340]'\n",
            "'[step-00002860] [time-5848.759] [total_loss-3.086805]  [loss0-0.332424]'\n",
            "'[step-00002870] [time-5865.617] [total_loss-1.246414]  [loss0-0.145875]'\n",
            "'[step-00002880] [time-5881.996] [total_loss-0.494510]  [loss0-0.048306]'\n",
            "'[step-00002890] [time-5902.698] [total_loss-2.235444]  [loss0-0.242856]'\n",
            "'[step-00002900] [time-5923.547] [total_loss-1.359968]  [loss0-0.167407]'\n",
            "'[step-00002910] [time-5940.006] [total_loss-6.677310]  [loss0-0.857930]'\n",
            "'[step-00002920] [time-5957.855] [total_loss-5.147941]  [loss0-0.709325]'\n",
            "'[step-00002930] [time-5977.679] [total_loss-2.215604]  [loss0-0.287395]'\n",
            "'[step-00002940] [time-6004.318] [total_loss-2.050485]  [loss0-0.273145]'\n",
            "'[step-00002950] [time-6021.932] [total_loss-0.949925]  [loss0-0.102937]'\n",
            "'[step-00002960] [time-6041.699] [total_loss-0.647157]  [loss0-0.065254]'\n",
            "'[step-00002970] [time-6058.737] [total_loss-2.718755]  [loss0-0.319168]'\n",
            "'[step-00002980] [time-6089.594] [total_loss-1.742158]  [loss0-0.223897]'\n",
            "'[step-00002990] [time-6120.560] [total_loss-1.498274]  [loss0-0.163297]'\n",
            "'[step-00003000] [time-6136.553] [total_loss-1.043451]  [loss0-0.099497]'\n",
            "results/training_cloth_segm_u2net_exp1/checkpoints/itr_00003000_u2net.pth\n",
            "'[step-00003010] [time-6168.156] [total_loss-0.617403]  [loss0-0.059189]'\n",
            "'[step-00003020] [time-6191.345] [total_loss-0.678375]  [loss0-0.068484]'\n",
            "'[step-00003030] [time-6219.336] [total_loss-2.095176]  [loss0-0.294970]'\n",
            "'[step-00003040] [time-6236.870] [total_loss-1.523938]  [loss0-0.191354]'\n",
            "'[step-00003050] [time-6256.373] [total_loss-2.146874]  [loss0-0.264790]'\n",
            "'[step-00003060] [time-6282.322] [total_loss-1.115477]  [loss0-0.108863]'\n",
            "'[step-00003070] [time-6307.482] [total_loss-1.629130]  [loss0-0.164795]'\n",
            "'[step-00003080] [time-6322.149] [total_loss-3.382123]  [loss0-0.460509]'\n",
            "'[step-00003090] [time-6336.540] [total_loss-3.986079]  [loss0-0.497936]'\n",
            "'[step-00003100] [time-6355.806] [total_loss-1.536907]  [loss0-0.209263]'\n",
            "'[step-00003110] [time-6372.069] [total_loss-1.547540]  [loss0-0.175637]'\n",
            "'[step-00003120] [time-6391.641] [total_loss-2.666072]  [loss0-0.383785]'\n",
            "'[step-00003130] [time-6406.667] [total_loss-2.387646]  [loss0-0.336392]'\n",
            "'[step-00003140] [time-6426.879] [total_loss-3.158705]  [loss0-0.413216]'\n",
            "'[step-00003150] [time-6440.888] [total_loss-0.359892]  [loss0-0.037490]'\n",
            "'[step-00003160] [time-6456.031] [total_loss-0.809026]  [loss0-0.100688]'\n",
            "'[step-00003170] [time-6470.952] [total_loss-1.683698]  [loss0-0.200263]'\n",
            "'[step-00003180] [time-6508.722] [total_loss-0.374976]  [loss0-0.039475]'\n",
            "'[step-00003190] [time-6524.189] [total_loss-0.454201]  [loss0-0.044213]'\n",
            "'[step-00003200] [time-6550.983] [total_loss-0.419369]  [loss0-0.045160]'\n",
            "'[step-00003210] [time-6569.955] [total_loss-1.144392]  [loss0-0.136574]'\n",
            "'[step-00003220] [time-6584.869] [total_loss-3.895192]  [loss0-0.471204]'\n",
            "'[step-00003230] [time-6600.551] [total_loss-2.564767]  [loss0-0.312951]'\n",
            "'[step-00003240] [time-6620.381] [total_loss-1.352030]  [loss0-0.149816]'\n",
            "'[step-00003250] [time-6636.362] [total_loss-0.520451]  [loss0-0.053144]'\n",
            "'[step-00003260] [time-6652.832] [total_loss-0.748845]  [loss0-0.078910]'\n",
            "'[step-00003270] [time-6667.751] [total_loss-4.622452]  [loss0-0.606783]'\n",
            "'[step-00003280] [time-6683.956] [total_loss-1.036905]  [loss0-0.121123]'\n",
            "'[step-00003290] [time-6699.960] [total_loss-0.527212]  [loss0-0.063400]'\n",
            "'[step-00003300] [time-6718.574] [total_loss-0.847067]  [loss0-0.101905]'\n",
            "'[step-00003310] [time-6734.410] [total_loss-0.579013]  [loss0-0.074875]'\n",
            "'[step-00003320] [time-6758.804] [total_loss-0.962768]  [loss0-0.100772]'\n",
            "'[step-00003330] [time-6777.155] [total_loss-0.778118]  [loss0-0.086491]'\n",
            "'[step-00003340] [time-6791.377] [total_loss-0.730495]  [loss0-0.073762]'\n",
            "'[step-00003350] [time-6808.376] [total_loss-1.501074]  [loss0-0.180202]'\n",
            "'[step-00003360] [time-6833.224] [total_loss-0.504342]  [loss0-0.049056]'\n",
            "'[step-00003370] [time-6859.036] [total_loss-1.633192]  [loss0-0.202142]'\n",
            "'[step-00003380] [time-6899.823] [total_loss-2.976500]  [loss0-0.369663]'\n",
            "'[step-00003390] [time-6915.154] [total_loss-1.062192]  [loss0-0.129440]'\n",
            "'[step-00003400] [time-6943.729] [total_loss-1.487072]  [loss0-0.178991]'\n",
            "'[step-00003410] [time-6970.169] [total_loss-2.833050]  [loss0-0.323924]'\n",
            "'[step-00003420] [time-6992.743] [total_loss-0.966316]  [loss0-0.100254]'\n",
            "'[step-00003430] [time-7011.029] [total_loss-1.475900]  [loss0-0.167565]'\n",
            "'[step-00003440] [time-7033.166] [total_loss-0.765916]  [loss0-0.092311]'\n",
            "'[step-00003450] [time-7047.889] [total_loss-2.373050]  [loss0-0.348368]'\n",
            "'[step-00003460] [time-7065.957] [total_loss-1.763087]  [loss0-0.196717]'\n",
            "'[step-00003470] [time-7088.469] [total_loss-1.051750]  [loss0-0.115971]'\n",
            "'[step-00003480] [time-7111.338] [total_loss-1.125582]  [loss0-0.136192]'\n",
            "'[step-00003490] [time-7129.130] [total_loss-1.726890]  [loss0-0.181909]'\n",
            "'[step-00003500] [time-7146.258] [total_loss-5.426347]  [loss0-0.619636]'\n",
            "'[step-00003510] [time-7165.247] [total_loss-0.728950]  [loss0-0.085954]'\n",
            "'[step-00003520] [time-7182.946] [total_loss-0.920536]  [loss0-0.104684]'\n",
            "'[step-00003530] [time-7198.819] [total_loss-0.939871]  [loss0-0.113001]'\n",
            "'[step-00003540] [time-7221.179] [total_loss-1.794297]  [loss0-0.223158]'\n",
            "'[step-00003550] [time-7236.764] [total_loss-0.465229]  [loss0-0.048141]'\n",
            "'[step-00003560] [time-7276.754] [total_loss-1.361240]  [loss0-0.169271]'\n",
            "'[step-00003570] [time-7299.689] [total_loss-0.575754]  [loss0-0.062268]'\n",
            "'[step-00003580] [time-7317.950] [total_loss-1.688005]  [loss0-0.221383]'\n",
            "'[step-00003590] [time-7338.136] [total_loss-0.263438]  [loss0-0.026271]'\n",
            "'[step-00003600] [time-7354.173] [total_loss-1.253637]  [loss0-0.165756]'\n",
            "'[step-00003610] [time-7377.087] [total_loss-0.608659]  [loss0-0.074057]'\n",
            "'[step-00003620] [time-7392.337] [total_loss-0.575997]  [loss0-0.069059]'\n",
            "'[step-00003630] [time-7408.069] [total_loss-2.034986]  [loss0-0.248276]'\n",
            "'[step-00003640] [time-7429.392] [total_loss-0.850399]  [loss0-0.112505]'\n",
            "'[step-00003650] [time-7445.087] [total_loss-0.598422]  [loss0-0.066865]'\n",
            "'[step-00003660] [time-7462.397] [total_loss-0.467017]  [loss0-0.051558]'\n",
            "'[step-00003670] [time-7479.443] [total_loss-1.425002]  [loss0-0.166914]'\n",
            "'[step-00003680] [time-7495.551] [total_loss-1.187117]  [loss0-0.127340]'\n",
            "'[step-00003690] [time-7510.379] [total_loss-2.042354]  [loss0-0.278315]'\n",
            "'[step-00003700] [time-7531.012] [total_loss-1.416435]  [loss0-0.179053]'\n",
            "'[step-00003710] [time-7551.837] [total_loss-4.127293]  [loss0-0.571311]'\n",
            "'[step-00003720] [time-7572.158] [total_loss-0.602558]  [loss0-0.065081]'\n",
            "'[step-00003730] [time-7592.293] [total_loss-1.999287]  [loss0-0.239013]'\n",
            "'[step-00003740] [time-7616.216] [total_loss-0.377371]  [loss0-0.038258]'\n",
            "'[step-00003750] [time-7644.512] [total_loss-2.263170]  [loss0-0.261204]'\n",
            "'[step-00003760] [time-7660.484] [total_loss-2.709852]  [loss0-0.316104]'\n",
            "'[step-00003770] [time-7678.916] [total_loss-0.203924]  [loss0-0.018344]'\n",
            "'[step-00003780] [time-7694.874] [total_loss-0.211776]  [loss0-0.023357]'\n",
            "'[step-00003790] [time-7716.011] [total_loss-5.607868]  [loss0-0.771215]'\n",
            "'[step-00003800] [time-7732.143] [total_loss-0.704487]  [loss0-0.077773]'\n",
            "'[step-00003810] [time-7748.309] [total_loss-0.693843]  [loss0-0.076027]'\n",
            "'[step-00003820] [time-7764.632] [total_loss-2.165579]  [loss0-0.273035]'\n",
            "'[step-00003830] [time-7779.641] [total_loss-1.393178]  [loss0-0.182628]'\n",
            "'[step-00003840] [time-7798.312] [total_loss-2.126408]  [loss0-0.254541]'\n",
            "'[step-00003850] [time-7815.996] [total_loss-2.485903]  [loss0-0.323076]'\n",
            "'[step-00003860] [time-7835.628] [total_loss-1.319155]  [loss0-0.152014]'\n",
            "'[step-00003870] [time-7850.328] [total_loss-1.058667]  [loss0-0.113087]'\n",
            "'[step-00003880] [time-7870.908] [total_loss-0.710878]  [loss0-0.075646]'\n",
            "'[step-00003890] [time-7886.948] [total_loss-1.338238]  [loss0-0.154263]'\n",
            "'[step-00003900] [time-7902.925] [total_loss-0.881222]  [loss0-0.108979]'\n",
            "'[step-00003910] [time-7920.599] [total_loss-4.646705]  [loss0-0.593719]'\n",
            "'[step-00003920] [time-7936.097] [total_loss-1.287602]  [loss0-0.128067]'\n",
            "'[step-00003930] [time-7951.481] [total_loss-0.632116]  [loss0-0.066667]'\n",
            "'[step-00003940] [time-7975.916] [total_loss-1.395869]  [loss0-0.180624]'\n",
            "'[step-00003950] [time-7995.219] [total_loss-1.355605]  [loss0-0.157648]'\n",
            "'[step-00003960] [time-8014.415] [total_loss-2.565497]  [loss0-0.334840]'\n",
            "'[step-00003970] [time-8029.397] [total_loss-0.652322]  [loss0-0.068513]'\n",
            "'[step-00003980] [time-8047.576] [total_loss-0.257702]  [loss0-0.024727]'\n",
            "'[step-00003990] [time-8076.024] [total_loss-1.083294]  [loss0-0.119395]'\n",
            "'[step-00004000] [time-8099.096] [total_loss-0.930108]  [loss0-0.112680]'\n",
            "results/training_cloth_segm_u2net_exp1/checkpoints/itr_00004000_u2net.pth\n",
            "'[step-00004010] [time-8118.811] [total_loss-0.527046]  [loss0-0.059780]'\n",
            "'[step-00004020] [time-8134.136] [total_loss-4.054494]  [loss0-0.555162]'\n",
            "'[step-00004030] [time-8177.530] [total_loss-0.866719]  [loss0-0.077269]'\n",
            "'[step-00004040] [time-8220.177] [total_loss-0.890224]  [loss0-0.105197]'\n",
            "'[step-00004050] [time-8239.498] [total_loss-0.318607]  [loss0-0.033045]'\n",
            "'[step-00004060] [time-8259.827] [total_loss-0.447299]  [loss0-0.060658]'\n",
            "'[step-00004070] [time-8280.058] [total_loss-1.323873]  [loss0-0.156532]'\n",
            "'[step-00004080] [time-8308.363] [total_loss-14.445416]  [loss0-1.917418]'\n",
            "'[step-00004090] [time-8323.350] [total_loss-1.328366]  [loss0-0.162636]'\n",
            "'[step-00004100] [time-8344.027] [total_loss-0.521230]  [loss0-0.061852]'\n",
            "'[step-00004110] [time-8359.531] [total_loss-0.629264]  [loss0-0.071314]'\n",
            "'[step-00004120] [time-8375.538] [total_loss-0.671016]  [loss0-0.072051]'\n",
            "'[step-00004130] [time-8394.367] [total_loss-0.443454]  [loss0-0.048612]'\n",
            "'[step-00004140] [time-8416.340] [total_loss-2.582874]  [loss0-0.354581]'\n",
            "'[step-00004150] [time-8438.865] [total_loss-1.883309]  [loss0-0.227136]'\n",
            "'[step-00004160] [time-8457.364] [total_loss-0.886420]  [loss0-0.103698]'\n",
            "'[step-00004170] [time-8474.259] [total_loss-1.553444]  [loss0-0.181126]'\n",
            "'[step-00004180] [time-8496.380] [total_loss-3.081537]  [loss0-0.415836]'\n",
            "'[step-00004190] [time-8512.948] [total_loss-1.566352]  [loss0-0.181394]'\n",
            "'[step-00004200] [time-8539.408] [total_loss-2.164392]  [loss0-0.260451]'\n",
            "'[step-00004210] [time-8560.638] [total_loss-2.292382]  [loss0-0.276911]'\n",
            "'[step-00004220] [time-8580.565] [total_loss-1.065528]  [loss0-0.105573]'\n",
            "'[step-00004230] [time-8598.900] [total_loss-0.343010]  [loss0-0.032954]'\n",
            "'[step-00004240] [time-8620.771] [total_loss-1.272166]  [loss0-0.152653]'\n",
            "'[step-00004250] [time-8640.396] [total_loss-0.609954]  [loss0-0.070357]'\n",
            "'[step-00004260] [time-8654.783] [total_loss-1.044633]  [loss0-0.111014]'\n",
            "'[step-00004270] [time-8669.860] [total_loss-2.676308]  [loss0-0.309210]'\n",
            "'[step-00004280] [time-8689.314] [total_loss-0.955387]  [loss0-0.111494]'\n",
            "'[step-00004290] [time-8704.646] [total_loss-0.337424]  [loss0-0.032557]'\n",
            "'[step-00004300] [time-8723.631] [total_loss-0.891103]  [loss0-0.089021]'\n",
            "'[step-00004310] [time-8747.838] [total_loss-1.239884]  [loss0-0.148625]'\n",
            "'[step-00004320] [time-8766.393] [total_loss-0.516913]  [loss0-0.049939]'\n",
            "'[step-00004330] [time-8785.269] [total_loss-0.535254]  [loss0-0.058574]'\n",
            "'[step-00004340] [time-8806.859] [total_loss-1.391377]  [loss0-0.176579]'\n",
            "'[step-00004350] [time-8821.420] [total_loss-1.715580]  [loss0-0.180521]'\n",
            "'[step-00004360] [time-8837.151] [total_loss-0.416579]  [loss0-0.045390]'\n",
            "'[step-00004370] [time-8856.344] [total_loss-1.124323]  [loss0-0.105325]'\n",
            "'[step-00004380] [time-8871.685] [total_loss-0.656497]  [loss0-0.071234]'\n",
            "'[step-00004390] [time-8888.713] [total_loss-0.369906]  [loss0-0.036513]'\n",
            "'[step-00004400] [time-8907.918] [total_loss-0.888149]  [loss0-0.096491]'\n",
            "'[step-00004410] [time-8925.710] [total_loss-2.238390]  [loss0-0.292203]'\n",
            "'[step-00004420] [time-8941.472] [total_loss-0.718865]  [loss0-0.087323]'\n",
            "'[step-00004430] [time-8958.679] [total_loss-9.980388]  [loss0-1.343326]'\n",
            "'[step-00004440] [time-8976.519] [total_loss-1.283131]  [loss0-0.167903]'\n",
            "'[step-00004450] [time-8993.337] [total_loss-0.561751]  [loss0-0.064901]'\n",
            "'[step-00004460] [time-9016.902] [total_loss-2.049437]  [loss0-0.244599]'\n",
            "'[step-00004470] [time-9031.887] [total_loss-0.656617]  [loss0-0.079995]'\n",
            "'[step-00004480] [time-9062.818] [total_loss-0.993813]  [loss0-0.114995]'\n",
            "'[step-00004490] [time-9078.682] [total_loss-2.591219]  [loss0-0.343018]'\n",
            "'[step-00004500] [time-9094.562] [total_loss-0.799635]  [loss0-0.094140]'\n",
            "'[step-00004510] [time-9113.793] [total_loss-0.713298]  [loss0-0.080148]'\n",
            "'[step-00004520] [time-9133.696] [total_loss-0.845125]  [loss0-0.091929]'\n",
            "'[step-00004530] [time-9156.887] [total_loss-0.454914]  [loss0-0.045483]'\n",
            "'[step-00004540] [time-9172.138] [total_loss-0.694967]  [loss0-0.081482]'\n",
            "'[step-00004550] [time-9187.918] [total_loss-0.487704]  [loss0-0.053454]'\n",
            "'[step-00004560] [time-9203.870] [total_loss-0.553386]  [loss0-0.062031]'\n",
            "'[step-00004570] [time-9222.331] [total_loss-0.581852]  [loss0-0.055090]'\n",
            "'[step-00004580] [time-9243.620] [total_loss-1.749976]  [loss0-0.214354]'\n",
            "'[step-00004590] [time-9259.433] [total_loss-0.966650]  [loss0-0.082808]'\n",
            "'[step-00004600] [time-9282.484] [total_loss-2.755926]  [loss0-0.327624]'\n",
            "'[step-00004610] [time-9300.836] [total_loss-1.487067]  [loss0-0.210196]'\n",
            "'[step-00004620] [time-9319.308] [total_loss-1.351728]  [loss0-0.170509]'\n",
            "'[step-00004630] [time-9339.047] [total_loss-0.975415]  [loss0-0.115357]'\n",
            "'[step-00004640] [time-9363.818] [total_loss-1.149300]  [loss0-0.139003]'\n",
            "'[step-00004650] [time-9385.630] [total_loss-0.962727]  [loss0-0.122915]'\n",
            "'[step-00004660] [time-9400.935] [total_loss-3.775149]  [loss0-0.460276]'\n",
            "'[step-00004670] [time-9424.099] [total_loss-0.643810]  [loss0-0.077249]'\n",
            "'[step-00004680] [time-9440.492] [total_loss-1.622650]  [loss0-0.184150]'\n",
            "'[step-00004690] [time-9458.360] [total_loss-2.519922]  [loss0-0.337824]'\n",
            "'[step-00004700] [time-9479.126] [total_loss-0.982703]  [loss0-0.124222]'\n",
            "'[step-00004710] [time-9504.047] [total_loss-0.818334]  [loss0-0.079880]'\n",
            "'[step-00004720] [time-9519.604] [total_loss-1.169854]  [loss0-0.132867]'\n",
            "'[step-00004730] [time-9545.908] [total_loss-0.465095]  [loss0-0.050013]'\n",
            "'[step-00004740] [time-9568.628] [total_loss-0.981641]  [loss0-0.119144]'\n",
            "'[step-00004750] [time-9592.134] [total_loss-0.449983]  [loss0-0.050355]'\n",
            "'[step-00004760] [time-9609.324] [total_loss-0.625611]  [loss0-0.079488]'\n",
            "'[step-00004770] [time-9628.707] [total_loss-2.509920]  [loss0-0.296319]'\n",
            "'[step-00004780] [time-9643.358] [total_loss-1.005651]  [loss0-0.131884]'\n",
            "'[step-00004790] [time-9658.391] [total_loss-2.700866]  [loss0-0.325068]'\n",
            "'[step-00004800] [time-9680.335] [total_loss-8.219403]  [loss0-1.039518]'\n",
            "'[step-00004810] [time-9700.877] [total_loss-0.864406]  [loss0-0.111139]'\n",
            "'[step-00004820] [time-9717.685] [total_loss-1.062130]  [loss0-0.124814]'\n",
            "'[step-00004830] [time-9732.732] [total_loss-0.820044]  [loss0-0.094046]'\n",
            "'[step-00004840] [time-9752.055] [total_loss-2.200773]  [loss0-0.269090]'\n",
            "'[step-00004850] [time-9786.355] [total_loss-0.709477]  [loss0-0.082514]'\n",
            "'[step-00004860] [time-9802.038] [total_loss-1.263565]  [loss0-0.130383]'\n",
            "'[step-00004870] [time-9833.519] [total_loss-1.321870]  [loss0-0.157965]'\n",
            "'[step-00004880] [time-9852.366] [total_loss-0.869053]  [loss0-0.092365]'\n",
            "'[step-00004890] [time-9867.717] [total_loss-0.719941]  [loss0-0.066011]'\n",
            "'[step-00004900] [time-9891.408] [total_loss-0.612014]  [loss0-0.071424]'\n",
            "'[step-00004910] [time-9909.363] [total_loss-0.978368]  [loss0-0.107333]'\n",
            "'[step-00004920] [time-9924.630] [total_loss-3.650761]  [loss0-0.479624]'\n",
            "'[step-00004930] [time-9942.080] [total_loss-0.994252]  [loss0-0.116112]'\n",
            "'[step-00004940] [time-9959.035] [total_loss-2.991668]  [loss0-0.375918]'\n",
            "'[step-00004950] [time-9973.857] [total_loss-0.854296]  [loss0-0.092280]'\n",
            "'[step-00004960] [time-9988.809] [total_loss-1.096287]  [loss0-0.133186]'\n",
            "'[step-00004970] [time-10003.946] [total_loss-0.591051]  [loss0-0.062822]'\n",
            "'[step-00004980] [time-10044.847] [total_loss-5.567500]  [loss0-0.731375]'\n",
            "'[step-00004990] [time-10063.884] [total_loss-1.152406]  [loss0-0.119088]'\n",
            "'[step-00005000] [time-10087.050] [total_loss-0.441310]  [loss0-0.049895]'\n",
            "results/training_cloth_segm_u2net_exp1/checkpoints/itr_00005000_u2net.pth\n",
            "'[step-00005010] [time-10106.413] [total_loss-0.583230]  [loss0-0.065263]'\n",
            "'[step-00005020] [time-10129.919] [total_loss-1.117910]  [loss0-0.128470]'\n",
            "'[step-00005030] [time-10151.927] [total_loss-0.466219]  [loss0-0.054878]'\n",
            "'[step-00005040] [time-10171.348] [total_loss-0.564085]  [loss0-0.063295]'\n",
            "'[step-00005050] [time-10197.295] [total_loss-1.425942]  [loss0-0.192133]'\n",
            "'[step-00005060] [time-10225.057] [total_loss-0.354987]  [loss0-0.035863]'\n",
            "'[step-00005070] [time-10239.990] [total_loss-2.020785]  [loss0-0.236636]'\n",
            "'[step-00005080] [time-10261.311] [total_loss-1.121596]  [loss0-0.115146]'\n",
            "'[step-00005090] [time-10284.181] [total_loss-1.474212]  [loss0-0.180076]'\n",
            "'[step-00005100] [time-10300.176] [total_loss-1.179938]  [loss0-0.124254]'\n",
            "'[step-00005110] [time-10322.874] [total_loss-1.901283]  [loss0-0.215825]'\n",
            "'[step-00005120] [time-10340.410] [total_loss-0.230729]  [loss0-0.022216]'\n",
            "'[step-00005130] [time-10360.175] [total_loss-0.445003]  [loss0-0.047494]'\n",
            "'[step-00005140] [time-10376.299] [total_loss-2.083082]  [loss0-0.271457]'\n",
            "'[step-00005150] [time-10395.933] [total_loss-8.101337]  [loss0-1.038338]'\n",
            "'[step-00005160] [time-10414.521] [total_loss-0.330740]  [loss0-0.037852]'\n",
            "'[step-00005170] [time-10432.401] [total_loss-1.015675]  [loss0-0.119502]'\n",
            "'[step-00005180] [time-10451.509] [total_loss-1.567298]  [loss0-0.202912]'\n",
            "'[step-00005190] [time-10474.498] [total_loss-2.450958]  [loss0-0.298011]'\n",
            "'[step-00005200] [time-10493.189] [total_loss-1.007359]  [loss0-0.109444]'\n",
            "'[step-00005210] [time-10509.864] [total_loss-1.384627]  [loss0-0.158149]'\n",
            "'[step-00005220] [time-10526.893] [total_loss-5.314938]  [loss0-0.734012]'\n",
            "'[step-00005230] [time-10545.609] [total_loss-0.392881]  [loss0-0.034093]'\n",
            "'[step-00005240] [time-10560.330] [total_loss-1.403014]  [loss0-0.134671]'\n",
            "'[step-00005250] [time-10575.287] [total_loss-1.223159]  [loss0-0.136199]'\n",
            "'[step-00005260] [time-10591.522] [total_loss-0.802545]  [loss0-0.085700]'\n",
            "'[step-00005270] [time-10606.062] [total_loss-1.148973]  [loss0-0.115217]'\n",
            "'[step-00005280] [time-10628.539] [total_loss-0.959771]  [loss0-0.102427]'\n",
            "'[step-00005290] [time-10644.196] [total_loss-0.937064]  [loss0-0.115823]'\n",
            "'[step-00005300] [time-10668.214] [total_loss-0.260144]  [loss0-0.021840]'\n",
            "'[step-00005310] [time-10685.472] [total_loss-0.455072]  [loss0-0.047865]'\n",
            "'[step-00005320] [time-10703.141] [total_loss-0.403401]  [loss0-0.052722]'\n",
            "'[step-00005330] [time-10721.956] [total_loss-0.518574]  [loss0-0.056310]'\n",
            "'[step-00005340] [time-10743.330] [total_loss-0.757350]  [loss0-0.094769]'\n",
            "'[step-00005350] [time-10766.438] [total_loss-0.258696]  [loss0-0.023379]'\n",
            "'[step-00005360] [time-10787.037] [total_loss-0.496878]  [loss0-0.054644]'\n",
            "'[step-00005370] [time-10803.655] [total_loss-0.875199]  [loss0-0.104920]'\n",
            "'[step-00005380] [time-10822.156] [total_loss-0.917247]  [loss0-0.102143]'\n",
            "'[step-00005390] [time-10839.274] [total_loss-0.849829]  [loss0-0.091814]'\n",
            "'[step-00005400] [time-10855.487] [total_loss-0.775702]  [loss0-0.089218]'\n",
            "'[step-00005410] [time-10872.407] [total_loss-8.456206]  [loss0-1.200716]'\n",
            "'[step-00005420] [time-10886.992] [total_loss-0.555526]  [loss0-0.066335]'\n",
            "'[step-00005430] [time-10904.942] [total_loss-0.439876]  [loss0-0.037084]'\n",
            "'[step-00005440] [time-10921.553] [total_loss-0.685894]  [loss0-0.072606]'\n",
            "'[step-00005450] [time-10936.565] [total_loss-0.709798]  [loss0-0.071104]'\n",
            "'[step-00005460] [time-10954.905] [total_loss-0.683866]  [loss0-0.074767]'\n",
            "'[step-00005470] [time-10973.354] [total_loss-1.375777]  [loss0-0.156452]'\n",
            "'[step-00005480] [time-10999.163] [total_loss-3.156645]  [loss0-0.401961]'\n",
            "'[step-00005490] [time-11027.942] [total_loss-0.323346]  [loss0-0.030261]'\n",
            "'[step-00005500] [time-11043.438] [total_loss-1.427163]  [loss0-0.157176]'\n",
            "'[step-00005510] [time-11063.519] [total_loss-0.696837]  [loss0-0.083277]'\n",
            "'[step-00005520] [time-11094.307] [total_loss-0.879119]  [loss0-0.108925]'\n",
            "'[step-00005530] [time-11110.203] [total_loss-2.101410]  [loss0-0.272718]'\n",
            "'[step-00005540] [time-11125.195] [total_loss-0.875179]  [loss0-0.109414]'\n",
            "'[step-00005550] [time-11149.229] [total_loss-0.506740]  [loss0-0.055951]'\n",
            "'[step-00005560] [time-11167.382] [total_loss-0.993986]  [loss0-0.114600]'\n",
            "'[step-00005570] [time-11194.953] [total_loss-0.864165]  [loss0-0.098893]'\n",
            "'[step-00005580] [time-11209.443] [total_loss-0.879398]  [loss0-0.099398]'\n",
            "'[step-00005590] [time-11229.445] [total_loss-2.885615]  [loss0-0.352234]'\n",
            "'[step-00005600] [time-11254.829] [total_loss-0.378502]  [loss0-0.049261]'\n",
            "'[step-00005610] [time-11273.457] [total_loss-1.048531]  [loss0-0.115275]'\n",
            "'[step-00005620] [time-11294.295] [total_loss-0.618353]  [loss0-0.072278]'\n",
            "'[step-00005630] [time-11309.199] [total_loss-0.753872]  [loss0-0.067601]'\n",
            "'[step-00005640] [time-11330.938] [total_loss-1.228937]  [loss0-0.157142]'\n",
            "'[step-00005650] [time-11345.640] [total_loss-0.472041]  [loss0-0.055735]'\n",
            "'[step-00005660] [time-11361.787] [total_loss-0.375025]  [loss0-0.028367]'\n",
            "'[step-00005670] [time-11394.672] [total_loss-1.345459]  [loss0-0.156928]'\n",
            "'[step-00005680] [time-11410.558] [total_loss-0.625441]  [loss0-0.070524]'\n",
            "'[step-00005690] [time-11434.047] [total_loss-0.415275]  [loss0-0.050114]'\n",
            "'[step-00005700] [time-11456.545] [total_loss-1.613957]  [loss0-0.195269]'\n",
            "'[step-00005710] [time-11473.650] [total_loss-0.787028]  [loss0-0.094713]'\n",
            "'[step-00005720] [time-11492.665] [total_loss-4.376408]  [loss0-0.556972]'\n",
            "'[step-00005730] [time-11517.968] [total_loss-0.607269]  [loss0-0.072610]'\n",
            "'[step-00005740] [time-11536.701] [total_loss-0.236566]  [loss0-0.022524]'\n",
            "'[step-00005750] [time-11553.550] [total_loss-0.553898]  [loss0-0.060409]'\n",
            "'[step-00005760] [time-11571.309] [total_loss-3.780714]  [loss0-0.496710]'\n",
            "'[step-00005770] [time-11592.640] [total_loss-0.262500]  [loss0-0.026614]'\n",
            "'[step-00005780] [time-11609.819] [total_loss-1.480327]  [loss0-0.159953]'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tUQe_vhIWTc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}